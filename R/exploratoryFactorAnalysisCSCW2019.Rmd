---
title: 'Factor analysis: n==2'
fig_width: 3.5
output:
  pdf_document: default
  html_document: default
fig_caption: yes
---

## Game plan for factor analysis: 
- Consistency is key: 
  - Filter for surveys only from users who worked with the *same* team sizes (n) and where *all users* completed the round we're analyzing
  - Follow notes for factor analysis in the section below

## Set-up packages // libraries and prepare for data import:
```{r echo=FALSE, include=FALSE, results='hide'}
library(jsonlite)
library(ggplot2)
library(lme4)
library(psych) # New for factor analysis
library(GPArotation) # New for factor analysis 
library(stargazer)
library(dplyr)
```

## Set-up directories, import and clean data:
```{r, include=TRUE, echo=TRUE}
rm(list=ls())
setwd("/Users/allieblaising/Desktop/bang/R") # Change this to your working directory where Bang/R file is located
getwd()
dataPath = "../data"
MINIMUM_BATCH_NUMBER = 1537266991708  # Identify the batch number that represents the start of the batches you'd like to include in your analysis 

TEAM_SIZE = 2 # Alter depending on team size in runs you're analyzing; this variable is used later on to ensure that you're filtering out all team_sizes != the size you've specified 

MIN_FRACTURE_PERCENT = 0.5 # Default cut off for fracture within a team; this variable is used later to label binary 0 (no fracture), 1 (fracture) values at a group level 

## Seperate viability function to deal with different column types
extractViabilitySurvey = function(frame,survey) {
  rounds = seq(1,4)
  roundResponses = lapply(rounds, function(round) {
    getCol = paste("results.",survey,".",round, sep="")
    surveyCols = Filter(function(x) grepl(getCol,x),names(frame))
    newCols = lapply(surveyCols, function(x) gsub(getCol,paste("results.",survey, sep=""),x) )
    surveyFrame = as.data.frame(frame[,surveyCols])
    if (is.null(newCols)) {return("No newCols")}
    names(surveyFrame) = newCols
    surveyFrame$id = frame$id
    surveyFrame$round = round
    surveyFrame$batch = frame$batch
    surveyFrame$rooms = frame$rooms
    #surveyFrame$room = frame$room
    surveyFrame$manipulationCheck.1 = frame$results.manipulationCheck.1
    #surveyFrame$blacklist = frame$results.blacklistCheck
    return(surveyFrame)
    print(surveyFrame)
  dim(surveyFrame)
  })
  return(Reduce(bind_rows, roundResponses))
}

# Filter batches and convert JSON to data frames
options(scipen=999) # Change from scientific notation so we can compare batch numbers below
batches = dir(dataPath, pattern = "^[0-9]+$" )
batches <- as.numeric(batches) 
batches = batches[batches>MINIMUM_BATCH_NUMBER]
batches = Filter(function(batch) {
  if (any(dir(paste(dataPath,batch,sep="/")) == "batch.json") && (any(dir(paste(dataPath,batch,sep="/")) == "users.json")) ) {
      batchData = read_json(paste(dataPath,batch,"batch.json",sep="/"), simplifyVector = TRUE)
      return(any(batchData$batchComplete == TRUE))
    }
    return(FALSE)
}, batches)

users <- Reduce(function(x,y) merge(x, y, all=TRUE), lapply(batches, function(batch) {
  userFile = read_json(paste(dataPath,batch,"users.json",sep="/"), simplifyVector=TRUE)
  return(flatten(userFile, recursive = TRUE))
}))

# Filter out variables not relevant to analysis: 
# Note: clear out problem columns 
users <- users %>% 
  filter(!is.na(results.viabilityCheck.1.10))

# Function to assign round numbers in the correct order 
usersRounds = as.data.frame(Reduce(rbind, apply(users,1,function(x) {
  roomsForIndividual = lapply(seq(1,4),function(y) {
    x$room = x$rooms[y]
    x$round = y
    return(x)
  })
  return(Reduce(rbind, roomsForIndividual))
})))

# Converting variables to their proper respective form for later analysis: 
usersRounds <- usersRounds %>% mutate(id = as.character(id), batch=as.numeric(batch), round=as.numeric(round), room=as.character(room), condition = as.character(results.condition))

viabilitySurvey <- extractViabilitySurvey(users, 'viabilityCheck')

usersRounds <- usersRounds %>%
  left_join(viabilitySurvey, by=c("id", "batch", "round")) %>%
  mutate(rooms = rooms.x)

# Extract only variables of interest for factory analysis: 

usersRounds <- usersRounds %>% select(id, batch, room, round, condition, results.viabilityCheck.1, results.viabilityCheck.2, results.viabilityCheck.3, results.viabilityCheck.4, results.viabilityCheck.5, results.viabilityCheck.6, results.viabilityCheck.7, results.viabilityCheck.8, results.viabilityCheck.9, results.viabilityCheck.10, results.viabilityCheck.11, results.viabilityCheck.12, results.viabilityCheck.13, results.viabilityCheck.14) %>% filter(!is.na(results.viabilityCheck.14)) 
 
# Calculate team sizes w/out summarising                                                                                                           
usersRounds <- usersRounds %>%
  arrange(id) %>%
  group_by(room, batch, round,condition) %>% 
  mutate(n = n())

# For consistency, filter for only dyads for first round exploratory factor analysis: 

usersRounds <- usersRounds %>% 
  filter(n == 2) 
```

## After data is imported and filtered based on conditions in *gameplan* begin analysis: 

# Background terms: 

EFA: Exploratory factor analysis: describes the data and summarizes "factors", often used as a first step on a scale or data. 
- Factors thought to cause the variables, and the underlying construct is what creates the scores. 
- Factors are produced, which is the term to use when writing up. 
- Only shared variables and unique variance is analyzed, the left over variance is considered error. 

Variance types: 
Common variance = overlapping variance between items (systematic variance)
Unique variance = variance only related to that item 
Communality = the common variance for the item (think of R^2 for that item)
EFA = describes common variance 
PCA = describes common variance + unique variance 

Correlation Matrices: 
Observed correlation matrix = the correlations between all the variables (like bivariate correlation chart) 
Reproduced correlation matrix = correlation matrix created from the factors created 
Residual correlation matrix = the difference between original and reproduced correlation matrix. 
The matrix will be very small if you had a good fit for your model. The residual matrices are used to calculate how well the analysis went. 

Eigenvalues = a mathematical representation of the variance accounted for by that grouping of itmes. 

# Checking parametric assumptions necessary for EFA and PCA: 
1. Variables: because EFA + PCA group variables into factors/components, only using 5 variables for example, doesn't allow us to create clusters easily. At least 10 variables are recommended. (CHECK)
2. Types of variables: interval or ration (CHECK)
3. Sample size 300 + generally agreed upon as best (CHECK - we have 666 observations w/ dyads, but this is including all rounds) 
4. Normal data screening: 
- Screen, accuracy, missing/outliers (CHECK) 
- Assumptions: addivity, linearity, normality, homogeneity and homoscedasticity (CHECK - see below code chunk, homogeneity is of partial concern)

```{r}
## Factor
levels <- c("Strongly Disagree", "Disagree", "Neutral","Agree", "Strongly Agree")
usersRounds <- usersRounds %>% ungroup() %>% 
  mutate_at(.vars = vars(contains("viabilityCheck")), funs(factor(., levels = levels))) 
usersNumeric <- usersRounds %>% mutate_if(is.factor, as.numeric) %>% select(contains("viabilityCheck")) #
data = usersNumeric 

## Addivity: 
correl = cor(data, use = "pairwise.complete.obs")
symnum(correl)
correl
# Addivity assumption met 

# Set up assumptions: 
## Normality: 
random = rchisq(nrow(data), 7) # 7 is abritary, anything above 2 is correct
fake = lm(random~., data = data)
standardized = rstudent(fake)
fitted = scale(fake$fitted.values)
hist(standardized)
# Some concerns about normality, left skewed. 

# Linearity 
qqnorm(standardized)
abline(0, 0) 

#Homogeneity
plot(fitted, standardized) 
abline(0, 0) 
abline(v = 0)
# Some concerns w/ homogeneity

```

# Checking correlation & sampling adequacy: 
- Bartlett's and KMO tests to determine is correlations are large enough for EFA (check - see code chunk below for results)

```{r}
# Correlation adequacy: 
print(cortest.bartlett(correl, n = nrow(data))) 

# Significant effect: p-value < 0.05, correlations are large enough for EFA 

# Sampling adequacy: 
KMO(correl)

# We are looking at whether the overall MSA is at least 0.7. Our overall MSA is 0.98, suggesting sampling adequacy for EFA. 
```


# Determing number of factors/components: 

```{r}
# How many factors? 
parallel <- fa.parallel(data, fm = 'ml', fa = 'fa') # ml = maximum likelihood
# This will output a "scree plot" 
# How to interpret plot: 
# Blue line: eigenvalues of actual data and two red lines show simulated and re-sampled data 
# Look at where there is a drop in actual data (blue line) and where it levels out 
# Also look at the point where the gap between simulated data (red) and actual data (blue) 
# tends to be minimial. 
# Use the above criteria to determine the range of factors that would be a good choice. 

# Parallel analysis output suggests that the number of factors = 1 

print(sum(parallel$fa.values > 1.0)) # Old Kaiser criterion 
print(sum(parallel$fa.values > .7)) # New Kaiser criterion 

# All three criterion indicators suggest we should use 1 factor 
```


# How do we achieve simple structure? 
- Factor rotation 
- Fitting estimation 

```{r}
# factors = n from above analysis 
#data.fa1 <- factanal(data, factors = 2, rotation="oblimin", fm = "ml")
#data.fa1
#data.fa5 <- factanal(data, factors = 2, rotation = "oblimin", scores = "regression")
#head(data.fa5$scores)
# Lots of output / analysis if there were more than 1 factor... But there isn't... 

data.fa1 <- factanal(data, factors = 1, fm = "ml")
data.fa1
```

# Is our solution / model adequate?  

*Fit indices interpretations:* 
1. Goodness of fit statistics: 
Goal is to have *Tucker Lew Index (TLI)* and *Comparative Fit Index (CFI)* to be greater than 0.90: 
- Our model TLI is 0.971  
- Out model 
2. Residual statistics: 
Goal is to have *Root mean square error of approximation (RMSEA)* and *Root mean square of the residual (RMSR)* <.10
- Our model RMSEA is 0.091 
- Our model RMSR is 0.01 

# Reliability: 
Estimating how much items "hang together" and might replicate 
- To do this, look at Cronbach's alpha, .70 and .80 is acceptable 

```{r}
# Reliability 
psych::alpha(data)
# Raw_alpha is 0.99, which is very good. 
```

## Theory: what do the factors mean? 
- Traditionally, here is where we would look at question themes and give the factors a label. But, because we only have one factor this step isn't possible right now... 

# Principal component analysis to look at importance of components: 

```{r}
# Pricipal Components Analysis
# entering raw data and extracting PCs 
# from the correlation matrix 
fit <- princomp(data, cor=TRUE)
summary(fit) # print variance accounted for 
loadings(fit) # pc loadings 
plot(fit,type="lines") # scree plot 
fit$scores # the principal components
biplot(fit)

# Varimax Rotated Principal Components
# retaining 5 components 
fit <- principal(data, nfactors=1, rotate="varimax")
fit # print results
```

# Taken together, one component is sufficient. 



