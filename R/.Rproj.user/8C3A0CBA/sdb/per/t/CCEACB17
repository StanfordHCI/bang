{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Asplode test outline\"\noutput: html_notebook\n---\n\n## Set-up packages // libraries and prepare for data import: \n```{r}\n## Uncomment install.packages and run outside of notebook environment: \n## install.packages(c(\"psych\" ,\"xtable\", \"tidyverse\", \"jsonlite\", \"likert\", \"ggplot2\", \"ploty\", \"mosaic\", \"modelr\", \"broom\"))\n\nlibrary(psych)\nlibrary(likert)\nlibrary(jsonlite)\nlibrary(ggplot2)\nlibrary(mosaic)\nlibrary(plotly)\nlibrary(modelr)\nlibrary(broom)\nsource(\"http://pcwww.liv.ac.uk/~william/R/crosstab.r\")\ntheme_set(theme_classic())\n```\n\n## Set-up directories, import and clean data: \n```{r}\nrm(list=ls())\nsetwd(\"/Users/allieblaising/desktop/bang/R\") \ngetwd()\ndataPath = \"../.data\"\n## Define function to extract survey results: \nextractSurvey = function(frame,survey) {\n  rounds = seq(1,length(frame$results.format[[1]]))\n  roundResponses = lapply(rounds, function(round) {\n    getCol = paste(\"results.\",survey,\".\",round, sep=\"\")\n    surveyCols = Filter(function(x) grepl(getCol,x),names(frame))\n    newCols = lapply(surveyCols, function(x) gsub(getCol,paste(\"results.\",survey, sep=\"\"),x) )\n    surveyFrame = frame[,surveyCols]\n    if (is.null(newCols)) {return(\"No newCols\")}\n    names(surveyFrame) = newCols\n    surveyFrame$id = frame$id\n    surveyFrame$round = round\n    surveyFrame$batch = frame$batch\n    surveyFrame$rooms = frame$rooms\n    surveyFrame$manipulation = frame$results.manipulationCheck\n    surveyFrame$blacklist = frame$results.blacklistCheck\n    # surveyFrame$results.qFifteenCheck.1 = frame$results.qFifteenCheck.1\n    # surveyFrame$results.qFifteenCheck.2 = frame$results.qFifteenCheck.2\n    # surveyFrame$results.qFifteenCheck.3 = frame$results.qFifteenCheck.3\n    # surveyFrame$results.qSixteenCheck.1 = frame$results.qSixteenCheck.1\n    # surveyFrame$results.qSixteenCheck.2 = frame$results.qSixteenCheck.2\n    # surveyFrame$results.qSixteenCheck.3 = frame$results.qSixteenCheck.3\n    return(surveyFrame)\n  })\n  return(Reduce(rbind, roundResponses))\n}\n#Find directory for import (be sure to verify that batch #s align from bangData import and imports below): \nbatches = dir(dataPath, pattern = \"^[0-9]+$\" )\ncompleteBatches = Filter(function(batch) { \n  if (any(dir(paste(dataPath,batch,sep=\"/\")) == \"batch.json\") && (any(dir(paste(dataPath,batch,sep=\"/\")) == \"users.json\")) ) {\n    batchData = read_json(paste(dataPath,batch,\"batch.json\",sep=\"/\"), simplifyVector = TRUE)\n    return(any(batchData$batchComplete == TRUE))\n  } \n  return(FALSE)\n}, batches)\nuserFiles = lapply(completeBatches, function(batch) {\n  userFile = read_json(paste(dataPath,batch,\"users.json\",sep=\"/\"), simplifyVector=TRUE)\n  return(flatten(userFile, recursive = TRUE))\n})\n\n## Retroactively find rooms from chat data: \noverlappingFiles = Reduce(function(x,y) merge(x, y, all=TRUE), userFiles)\nroundsWithRooms = apply(overlappingFiles,1,function(x) {\n  roomsForIndividual = lapply(seq(1,3),function(y) {\n    x$room = x$rooms[y]\n    x$round = y\n    return(x)\n  })\n  return(Reduce(rbind, roomsForIndividual))\n})\nlibrary(tidyverse)\n\n## To filter the right batch numbers, add the first batch number for our runs (i.e. batch >= \"first batch #\") \n\n## overlappingFiles <- overlappingFiles %>% filter(batch==\"1536132233074\")\n\n```\n\n## More cleaning before visualizations: \n```{r}\n## Apply extract survey function to extract the right columns and rows for viability survey: \nsurvey = 'viabilityCheck'\nframe <- extractSurvey(overlappingFiles, survey) \n## Reduce to vertically combine rows in roundwithRooms list:  \nfinalRounds = as.data.frame(Reduce(rbind,roundsWithRooms))\n## Subset incomplete cases from viability survey dataframe, use manipulation check b/c required for complete observation: \ndata <- frame[frame$manipulation!=\"\",]\n## Rename room to rooms so that both are retained in future merge: \ndata <- rename(data, rooms = \"rooms\")\n## Subset incomplete cases for final rounds dataframe: \ndata2 <- finalRounds[finalRounds$results.manipulationCheck!=\"\", ]\n## Select only variables of interest from final rounds: \ndata2 = data2 %>% select(id, batch, room, bonus, name, friends, \n                         friends_history, results.condition, results.format,\n                  results.manipulation,results.manipulationCheck,results.blacklistCheck, round)\n## Convert to compatible data types before merge (**this should be simplified**)\ndata2$batch <- unlist(data2$batch)\ndata2$round <- unlist(data2$round)\ndata2$id <- unlist(data2$id) \ndata$batch <- unlist(data$batch)\n\n## Before merge, data and data2 should have the same # of observations\n## Merge columns by id, round and batch #s: \ndata <- left_join(data, data2, by=NULL)\n## Subset only observations with batch #s in complete batches \nallConditions <- data[data$batch %in% completeBatches, ]\n```\n## Conditionally assign conditions based on treatment and results column: \n```{r}\n## Messy, but robust? Verify, verify, verify people:   \ndata <- data %>% mutate(\n  condition = case_when(\n    results.condition=='treatment' & results.format==\"c(1, 2, 1)\" & round==1 ~ \"A\", \n    results.condition=='treatment' & results.format==\"c(1, 2, 1)\" & round==2 ~ \"B\", \n    results.condition=='treatment' & results.format==\"c(1, 2, 1)\" & round==3 ~ \"Ap\", \n    results.condition=='treatment' & results.format==\"c(1, 1, 2)\" & round==1 ~ \"A\", \n    results.condition=='treatment' & results.format==\"c(1, 1, 2)\" & round==2 ~ \"Ap\", \n    results.condition=='treatment' & results.format==\"c(1, 1, 2)\" & round==3 ~ \"B\", \n    results.condition=='treatment' & results.format==\"c(2, 1, 1)\" & round==1 ~ \"B\", \n    results.condition=='treatment' & results.format==\"c(2, 1, 1)\" & round==2 ~ \"A\", \n    results.condition=='treatment' & results.format==\"c(2, 1, 1)\" & round==3 ~ \"Ap\" ,\n    results.condition=='control' & results.format==\"c(1, 2, 1)\" & round==1 ~ \"A\", \n    results.condition=='control' & results.format==\"c(1, 2, 1)\" & round==2 ~ \"B\", \n    results.condition=='control' & results.format==\"c(1, 2, 1)\" & round==3 ~ \"Ap\", \n    results.condition=='control' & results.format==\"c(1, 1, 2)\" & round==1 ~ \"A\", \n    results.condition=='control' & results.format==\"c(1, 1, 2)\" & round==2 ~ \"Ap\", \n    results.condition=='control' & results.format==\"c(1, 1, 2)\" & round==3 ~ \"B\", \n    results.condition=='control' & results.format==\"c(2, 1, 1)\" & round==1 ~ \"B\", \n    results.condition=='control' & results.format==\"c(2, 1, 1)\" & round==2 ~ \"A\", \n    results.condition=='control' & results.format==\"c(2, 1, 1)\" & round==3 ~ \"Ap\" , \n    results.condition=='baseline' & results.format==\"1:3\" & round==1 ~ \"A\" ,\n    results.condition=='baseline' & results.format==\"1:3\" & round==2 ~ \"B\" ,\n    results.condition=='baseline' & results.format==\"1:3\" & round==3 ~ \"C\" \n  )) \n\n\n```\n\n## Set-up for factors for viability questions: \n```{r}\ndata <- rename(data, \"repeatTeam\" = results.viabilityCheck.15)\n## Remove observations where viability survey wasn't on (remove this line if we want to keep observations with viability off): \ndata <- na.omit(data)\n## Factor for visualizations: \nlevels <- c(\"Strongly Disagree\", \"Disagree\", \"Neutral\",\"Agree\", \"Strongly Agree\") \nclean <- data %>% \n  mutate_at(.vars = vars(contains(\"results.viabilityCheck\")), funs(factor(., levels = levels))) \n## Create a new dataframe that converts factors to numeric for statistical analyses:\nstats <- clean %>% mutate_if(is.factor, as.numeric)\nfor (i in 1:nrow(stats)) {\n  stats$sum[i] <- sum(stats[i,1:14])                          \n} \nstats$median <- median(stats$sum)\nstats$mean <- mean(stats$sum)\n## Revalue repeat team: keep plyr b/c some weird R stuff requires library to be called directly (recode values to )\nstats$repeatTeam <- plyr::revalue(stats$repeatTeam, c(\"Yes\"=\"0\", \"No\"=\"1\"))\nstats$repeatTeam <- plyr::revalue(stats$repeatTeam, c(\"Keep this team\"=\"0\", \"Do not keep this team\"=\"1\"))\n## Convert to compatible classes for team grouping: \nstats$repeatTeam <- as.numeric(stats$repeatTeam)\nstats$results.condition <- unlist(stats$results.condition)\nstats$results.format <- as.character(stats$results.format)\nstats$room <- unlist(stats$room)\n## Dplyr to group teams and summarise variables for each group: group_by to find teams and summarise to compact individual results into group level results (i.e. one row of variable results per team)\ngroupedProportion <- stats %>%\n  group_by(room, batch, round, condition, results.condition, results.format) %>%  ## to-do: add group ID in storage db. \n  summarise(n=n(), mean=mean(sum), median=median(sum),prop=sum(repeatTeam)/n, groupID=runif(1,0,2)) %>% \n## Filter out all teams with n=1 (i.e. a person in a one person team) \n  filter(n==2)\n\n## Individual proportion: \nindividualProportion <- stats %>% group_by(round, batch, room) %>% \n  mutate(sum=sum, mean=mean(sum), median=median(sum), n=n(),prop=sum(repeatTeam)/n) %>% \n  filter(n>1)\n\n## Table showing how many teams we've run in each condition combination:  \n## print(table(groupedProportion$condition, groupedProportion$results.condition)) \n```\n\n## Probability of fracture across teams and condition combinations: \n```{r}\n## Define and initialize cut-off point for fracture: \ngroupedProportionFracture <- groupedProportion %>%\n  group_by(results.condition, condition) %>% \n  mutate(fracture = case_when (prop<.50 ~ \"0\", \n                                prop>=.50~ \"1\")) \n\n## Baseline: (we probably won't need this since we are artificially making baseline conditions)\n# groupedProportionFractureBaseline <- \n#   groupedProportionFracture %>% \n# filter(results.condition==\"baseline\") %>% \n#   filter(id %in% condition==\"A\" & condition==\"C\")\n# baselineFracture1 <- groupedProportionFractureBaseline %>% filter(condition==\"A\")\n# baselineFracture2 <- groupedProportionFractureBaseline %>% filter(condition==\"C\")\n\n# TO-DO: check if this is right--seems off\n\ngroupedProportionFractureBaseline <- groupedProportionFracture %>% filter(results.format==\"c(1, 1, 2)\" | results.format==\"c(2, 1, 1)\") %>% filter(round==\"1\" | round==\"3\") \n# baselineFracture1 <- groupedProportionFractureBaseline %>% filter(round==\"1\")\n# baselineFracture2 <- groupedProportionFractureBaseline %>% filter(round==\"3\")\n# baselineFracture1$fracture15 <- baselineFracture1$fracture\n# baselineFracture2$test2 <- baselineFracture2$fracture\n# ## Below only combines if teams are in both round 1 & 3 together: \n# baselineFracture <- left_join(baselineFracture1, baselineFracture2, by=NULL, drop=TRUE)\n\n## Treatment: \ngroupedProportionFractureTreatment <- groupedProportionFracture %>% \nfilter(results.condition==\"treatment\")\ntreatmentFracture1 <- groupedProportionFractureTreatment %>% filter(condition==\"A\")\ntreatmentFracture2 <- groupedProportionFractureTreatment %>% filter(condition==\"Ap\")\ntreatmentFracture <- cbind(treatmentFracture1, treatmentFracture2)\n\n## Control:  \ngroupedProportionFractureControl <- groupedProportionFracture %>% \n  filter(results.condition==\"control\") \ncontrolFracture1 <- groupedProportionFractureControl %>% filter(condition==\"A\")\ncontrolFracture2 <- groupedProportionFractureControl %>% filter(condition==\"Ap\")\ncontrolFracture <- cbind(controlFracture1, controlFracture2)\n\n## Manipulation check: \n## Use individual proportion data frame b/c we're interested in looking at individuals that were in teams >n=1\nteamPatterns <- \"Team 1 and Team 2|Team 1 and Team 3|Team 2 and Team 3\"\nindividualProportion$manipulationAnswerKey <- str_extract(individualProportion$results.manipulationCheck,teamPatterns) \nindividualProportion$manipulationAnswers <- individualProportion$results.manipulation\nindividualProportion$results.condition = unlist(individualProportion$results.condition)\n## Omit NAs and results that can't be processed: \ncleanManipulation <- individualProportion[with(individualProportion, grepl(teamPatterns, manipulationAnswers) & grepl(teamPatterns, manipulationAnswerKey)),]\n## Transform into compatiable form: \ncleanManipulation$manipulationAnswers = unlist(cleanManipulation$manipulationAnswers)\n```\n\n## Section #1: Does fracture have continuity with prior measures?\n\n## 1A: Report the % of correct guesses on the manipulation check: \n```{r}\n## Treatment manipulation: \ntreatmentManipulation <- cleanManipulation %>% group_by(id, results.condition, manipulationAnswers, manipulationAnswerKey) %>% filter(results.condition==\"treatment\") %>% \n  summarise(n=n()) \n## If user manipulation answers == manipulation answer key then add 1 \ntreatmentManipulation$correctAnswers <- sum(ifelse(treatmentManipulation$manipulationAnswers==treatmentManipulation$manipulationAnswerKey,1,0))\n## Calculate percent of correct manipulation answers for treatment: \ntreatmentManipulation <- treatmentManipulation %>% mutate(percentCorrect = (correctAnswers/(nrow(treatmentManipulation))))\nprint(treatmentManipulation)\n\n## Control manipulation: \ncontrolManipulation <- cleanManipulation %>% group_by(id, results.condition, manipulationAnswers, manipulationAnswerKey) %>% filter(results.condition==\"control\") %>% \n  summarise(n=n()) \n## If user manipulation answers == manipulation answer key then add 1 \ncontrolManipulation$correctAnswers <- sum(ifelse(controlManipulation$manipulationAnswers==controlManipulation$manipulationAnswerKey,1,0))\n## Calculate percent of correct manipulation answers for control: \ncontrolManipulation <- controlManipulation %>% mutate(percentCorrect = (correctAnswers/(nrow(controlManipulation))))\nprint(controlManipulation)\n## Proportion test comparing treatment manipulation percent correct with chance: \n```\n\n## 1B: Proportion test comparing treatment manipulation percent correct with chance: \n```{r}\n## ⅓ ~ 33% = chance, ~43 = treatment (FILL-IN EACH TIME YOU RUN WITH NEW DATA!)\n\npropManipulation <- prop.test(x = c(33, 43), n = c(100, 100))\nprint(propManipulation)\n```\n\n## 1C: Logistic regression predicting binary fracture outcome from viability scales: \n```{r}\n## Split data into 60% training and 40% testing data sets to test how well the model performs \nset.seed(123)\ngroupedProportionFracture$fracture <- as.numeric(groupedProportionFracture$fracture) \nsample <- sample(c(TRUE, FALSE), nrow(groupedProportionFracture), replace = T, prob = c(0.6,0.4))\ntrain <- groupedProportionFracture[sample, ]\ntest <- groupedProportionFracture[!sample, ]\n\n## Simple logistic regression: we will fit a logistic regression model in order to predict \n## the probability of fracture based on a team's average viability sum: \n\nmodel1 <- glm(fracture ~ mean, family = \"binomial\", data = train)\nsummary(model1)\n\n## To assess the linear regression deviance, look at deviance in summary output, if \n## deviance == sum of sqaures in linear regression, null deviance == difference between \n## a model with only the intercept (\"no mean predictors\") and the a saturated model \n## a model with a theoretically perfect fit. Model deviance (residual deviance) should be lower \n## small values == better fit. \n\ntidy(model1)\n## Coefficient estimtes from log regression characterize relationship between the predictor and \n## response variable on a log-odds scale, so binary increase from no fracture - fracture can be interpreted as associated with a decrease in mean viability sum. \n\n## More coefficient output: measure the confidence intervals and accuracy of the coefficent: \nconfint(model1)\n\n## Making predictions: \n## What is the probability of fracture given the following team mean viability scores: for example purposes: 40 and 65: \n\npredict(model1, data.frame(mean = c(50, 65)), type = \"response\")\n\n## From the output, we can see that the probability of fracture decreases by ~40% when mean viability sum increases from 40 to 65. \n\n## Model evaluation & diagnostics: \n## How well does the model fit the data? And how accurate are the predictions on an out-of-sample data set?\n\n## Residul assessment: \n\nmodel1_data <- augment(model1) %>% \n  mutate(index = 1:n())\n\nggplot(model1_data, aes(index, .std.resid, color = mean)) + \n  geom_point(alpha = .5) +\n  geom_ref_line(h = 3)\n\n## Validation of predicted values: \n## How well does the model perform when predicting the target variable on out-of-sample observations? \n\ntest.predicted.m1 <- predict(model1, newdata = test, type = \"response\")\n\n## Classification performance for each model on the test data. Output gives us a list of true / false positives: \n\nlist(\n  model1 = table(test$mean, test.predicted.m1 > 0.5) %>% prop.table() %>% round(3)) \n\ntable(test$mean, test.predicted.m1 > 0.5)\n```\n## 1D: Graph of fracture/no fracture vs. mean/stdev viability scale\n```{r}\n## Overall: \ng <- ggplot(groupedProportionFracture, aes(factor(fracture), mean)) \ng + geom_boxplot(varwidth=T, fill=\"plum\") + \n  labs(subtitle=\"Team fracture value vs. mean viability score: fracture >=0.50 across all conditions (n=2)\", \n       x=\"\",\n       y=\"Numeric sum of viability measures questions (range: 7-70)\") \n\n## By condition + format: \ng <- ggplot(groupedProportionFracture, aes(factor(fracture), mean)) \ng + geom_boxplot(varwidth=T, fill=\"plum\") + \n  labs(subtitle=\"Team fracture value vs. mean viability score: fracture >=0.50 (n=2)\", \n       x=\"\",\n       y=\"Numeric sum of viability measures questions (range: 7-70)\") + facet_grid(condition ~ results.condition) \n\nggplot(data=groupedProportionFracture, aes(fracture, mean)) + \n   geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") + labs(main=\"Scatterplot of fracture value vs. mean for team viability sums across all conditions (n=2)\") +  facet_grid(condition ~ results.condition) \n\nggplot(data=groupedProportionFracture, aes(fracture, mean)) + \n   geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") + labs(main=\"Scatterplot of fracture value vs. mean for team viability sums (n=2)\") +  facet_grid(condition ~ results.condition) \n```\n\n## Section #2: How often does fracture occur?\n\n## 2A: P(binary fracture) histogram of fracture proportion (by team)\n```{r}\n## First make sure you've made ABC condition\nggplot(data=groupedProportion, aes(groupedProportion$prop)) + \n  geom_histogram(breaks=seq(0, 1, by=0.20), \n                 col=\"red\", \n                 fill=\"green\", \n                 alpha=.2) + labs(title=\"Frequency of team fracture proportions by condition and pattern sequence\", \n                                  x=\"team fracture proportion\", y=\"Count\") + facet_grid(results.condition ~ .) \n\nlibrary(MASS)     \n\n## Test if whether fracture smoking habit is independent of condition at .05 significance level: \n\nchi = table(groupedProportionFracture$fracture, groupedProportionFracture$results.condition)  \nchi\nprint(chisq.test(chi)) \n```\n\n## 2B: What's the overall % of fracturing the second time? (by condition)\n```{r}\n## Filtering second time only: \ngroupedProportionFracture$fracture <- as.numeric(groupedProportionFracture$fracture)\n\n## TO-DO: review below code, worried it's incorrect: \n\ngroupedProportionFractureSecond <- groupedProportionFracture %>% group_by(results.condition) %>% \n      filter(condition==\"Ap\") %>% \n      mutate(overallPercent = sum(as.numeric(fracture))) %>% \n      summarise(n=n(), overallPercent=unique(overallPercent)/n) \nprint(groupedProportionFractureSecond)\n\n## For baseline theoretical distribution: (to-do: look over this, worried also that it's wrong)\n\ngroupedProportionFractureSecondBase <- groupedProportionFractureBaseline %>% \n      filter(round==\"3\") %>% \n      summarise(n=n(), overallPercent=sum(as.numeric(fracture))/n) \nprint(mean(groupedProportionFractureSecondBase$overallPercent))\n\n## Set-up separate groups for proportion tests to answer: does unmasked fracture more/less than masked \n## and more/less than new pairs? \n\n## Control: \n\n## Proportion tests for each (TO-DO, figure out argument stuff: this doesn't seem like the right test to run for the question we're asking?) also, fill-this in every time you get new data: \n\n\n## Is the proportion of fracture in the second round significantly different in the two conditions (i.e. treatment + baseline) \ntreatmentvsBaselineChange <- c(48, 49)\npropFractureChangeTreatmentvsBase <- prop.test(x = c(treatmentvsBaselineChange), n = c(100, 100))\nprint(propFractureChangeTreatmentvsBase) \n\n## Is the proportion of fracture in the second round significantly different in the two conditions (i.e. control + baseline) \ncontrolvsBaselineChange <- c(40, 49)\npropFractureChangeControlvsBase <- prop.test(x = c(controlvsBaselineChange), n = c(100, 100))\nprint(propFractureChangeControlvsBase)\n```\n## Section 3: How consistent is fracture? \n\n## 3A: calculating the conditional probabilities of fracture for each condition: \n```{r}\nconditionalProbTreatment <- groupedProportionFractureTreatment %>% filter(condition==\"A\" | condition==\"Ap\")\ntally(~fracture | condition, data = conditionalProbTreatment, format = \"proportion\")\n\nconditionalProbControl <- groupedProportionFractureControl %>% filter(condition==\"A\" | condition==\"Ap\")\ntally(~fracture | condition, data = conditionalProbControl, format = \"proportion\")\n\nconditionalProbBaseline <- groupedProportionFractureBaseline  %>% filter(condition==\"A\" | condition==\"C\")\ntally(~fracture | condition, data = conditionalProbBaseline, format = \"proportion\")\n\n## If fractured the first time, what's the % of fracturing the second time? look at 1 and Ap combination for % in second time: \n\n## Compare both treatment and control with baseline as theoretical distribution: \n```\n\n## 3B: Now investigating the big result: switch %: what's the % of pairs flipping their decisions?\n\n```{r}\n## Convert format before merge: *this can be simplified*: \n\ntreatmentFracture2$fracture <- as.numeric(treatmentFracture2$fracture) \ntreatmentFracture1$fracture <- as.numeric(treatmentFracture1$fracture) \ntreatmentFracture$absFracture <- abs(treatmentFracture2$fracture-treatmentFracture1$fracture)\n\ncontrolFracture1$fracture <- as.numeric(controlFracture1$fracture)\ncontrolFracture2$fracture <- as.numeric(controlFracture2$fracture)\ncontrolFracture$absFracture <- abs(controlFracture2$fracture-controlFracture1$fracture)\n\nbaselineFracture$fracture1 <- as.numeric(baselineFracture$fracture1) \nbaselineFracture$fracture2 <- as.numeric(baselineFracture$fracture2) \nbaselineFracture$absFracture <- abs(baselineFracture$fracture1-baselineFracture$fracture2)\n\n## Results here seem fishy? Triple check my code for abs/sum? \n\ntreatmentFractureAbsSum <- sum(treatmentFracture$absFracture) \nprint(treatmentFractureAbsSum)\ncontrolFractureAbsSum <- sum(controlFracture$absFracture)\nprint(controlFractureAbsSum)\n## baselineFractureAbsSum <- sum(baselineFracture$absFracture) \n\n\n## Don't we want a proportion test here before adding / trying chi-squared? \n\ntreatmentAbsChange=c(15) \ncontrolAbsChange=c(1)\n\n## Using baseline as theoretical probability distribution \n## Treatment: \nchisq.test(treatmentAbsChange,p=baselineAbsChange)\n\n## Control:\nchisq.test(controlAbsChange,p=baselineAbsChange)\n```\n\n## Visualizing change: \n\n```{r}\n## Visualize differences: \n\ndat <- data.frame(changesPerCondition= factor(c(\"Sum of absolute fracture change in treatment >=.50\",\"Sum of absolute fracture change in control >=.50\"), levels=c(\"Sum of absolute fracture change in treatment >=.50\",\"Sum of absolute fracture change in control >=.50\")),\n                  fractureValueSwitch = c(15, 1))\n\np <- ggplot(data=dat, aes(x=changesPerCondition, y=fractureValueSwitch)) +\n  geom_bar(stat=\"identity\")\np <- ggplotly(p)\np\n```\n\n\n\n\n\n\n\n\n",
    "created" : 1536901828272.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2830934219",
    "id" : "CCEACB17",
    "lastKnownWriteTime" : 1536734414,
    "last_content_update" : 1536734414,
    "path" : "~/Documents/bang9/R/asplodePaperOutline.Rmd",
    "project_path" : "asplodePaperOutline.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}