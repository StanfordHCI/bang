---
title: "Fracture CHI 2019 Results >=.5"
output:
  html_document:
    fig_caption: yes
  pdf_document: default
---

## Set-up packages // libraries and prepare for data import: 
```{r echo=FALSE, include=TRUE, results='hide'}
## Uncomment install.packages and run outside of notebook environment: 
## install.packages(c("psych" ,"xtable", "tidyverse", "jsonlite", "likert", "ggplot2", "ploty", "mosaic", "modelr", "broom", "scales"))
library(psych)
library(likert)
library(jsonlite)
library(ggplot2)
library(plotly)
library(modelr)
library(broom)
library(scales)
theme_set(theme_classic())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(stargazer)
```

## Set-up directories, import and clean data: 
```{r, include=TRUE, echo=TRUE, results='hide'} 
rm(list=ls())
setwd("/Users/allieblaising/desktop/bang/R") 
getwd()
dataPath = "../.data"

## Function to extract blacklist surveys: 
extractBlacklistSurvey = function(frame,survey) {
  rounds = seq(1,4)
  roundResponses = lapply(rounds, function(round) {
    getCol = paste("results.",survey,".",round, sep="")
    surveyCols = Filter(function(x) grepl(getCol,x),names(frame))
    newCols = lapply(surveyCols, function(x) gsub(getCol,paste("results.",survey, sep=""),x) )
    surveyFrame = as.data.frame(frame[,surveyCols]) 
    if (is.null(newCols)) {return("No newCols")}
    names(surveyFrame) = newCols
    surveyFrame$id = frame$id
    surveyFrame$round = round
    surveyFrame$batch = frame$batch
    surveyFrame$rooms = frame$rooms
    surveyFrame$blacklist = frame$results.blacklistCheck
    return(surveyFrame)
  })
  return(Reduce(rbind, roundResponses))
}

#Find directory for import (be sure to verify that batch #s align from bangData import and imports below):
batches = dir(dataPath, pattern = "^[0-9]+$" )
completeBatches = Filter(function(batch) { 
  if (any(dir(paste(dataPath,batch,sep="/")) == "batch.json") && (any(dir(paste(dataPath,batch,sep="/")) == "users.json")) ) {
    batchData = read_json(paste(dataPath,batch,"batch.json",sep="/"), simplifyVector = TRUE)
    return(any(batchData$batchComplete == TRUE))
  } 
  return(FALSE)
}, batches)
## Debug: if you get error with flatten, you need to unload tidyverse in package column to the right:  
userFiles = lapply(completeBatches, function(batch) {
  userFile = read_json(paste(dataPath,batch,"users.json",sep="/"), simplifyVector=TRUE)
  return(flatten(userFile, recursive = TRUE))
})
## Retroactively find rooms from chat data: 
overlappingFiles = Reduce(function(x,y) merge(x, y, all=TRUE), userFiles)

## Important: below is where you define the scope of your analysis, make sure this is set to include the right batches: 
overlappingFiles <- overlappingFiles %>% filter(batch=="1536960730305")
roundsWithRooms = apply(overlappingFiles,1,function(x) {
  roomsForIndividual = lapply(seq(1,4),function(y) {
    x$room = x$rooms[y]
    x$round = y
    return(x)
  })
  return(Reduce(rbind, roomsForIndividual))
})
## Libraries that we'll need but conflict with other stuff: 
library(tidyverse)
library(mosaic)
library(data.table)
library(car)
## To filter the right batch numbers, add the first batch number for our runs (i.e. batch >= "first batch #") 
# overlappingFiles <- overlappingFiles %>% filter(batch=="1536335493362")

## To filter later on batch ##: 
options(scipen=999)

## Seperate viability function to deal with different column types 
extractViabilitySurvey = function(frame,survey) {
  rounds = seq(1,4)
  roundResponses = lapply(rounds, function(round) {
    getCol = paste("results.",survey,".",round, sep="")
    surveyCols = Filter(function(x) grepl(getCol,x),names(frame))
    newCols = lapply(surveyCols, function(x) gsub(getCol,paste("results.",survey, sep=""),x) )
    surveyFrame = as.data.frame(frame[,surveyCols]) 
    if (is.null(newCols)) {return("No newCols")}
    names(surveyFrame) = newCols
    surveyFrame$id = frame$id
    surveyFrame$round = round
    surveyFrame$batch = frame$batch
    surveyFrame$rooms = frame$rooms
    surveyFrame$manipulation = frame$results.manipulationCheck
    surveyFrame$blacklist = frame$results.blacklistCheck
    return(surveyFrame)
    print(surveyFrame)
  dim(surveyFrame)
  })
  return(Reduce(bind_rows, roundResponses))
}
```

## More cleaning before visualizations: 
```{r, include=TRUE, echo=TRUE, message=FALSE} 
## Extract relevant surveys: 
qFifteen <- extractBlacklistSurvey(overlappingFiles, 'qFifteenCheck')
qSixteen <- extractBlacklistSurvey(overlappingFiles, 'qSixteenCheck')
viabilitySurvey <- extractViabilitySurvey(overlappingFiles, 'viabilityCheck')
postSurveyQs <- cbind(qFifteen, qSixteen)
frame <- cbind(viabilitySurvey, postSurveyQs)
data <- frame[, !duplicated(colnames(frame))]
## Reduce to vertically combine rows in roundwithRooms list:  
finalRounds = as.data.frame(Reduce(rbind,roundsWithRooms))
## Subset incomplete cases from viability survey dataframe, use manipulation check b/c required for complete observation: 
data <- data[data$manipulation!="",]
## Rename room to rooms so that both are retained in future merge: 
data <- rename(data, rooms = "rooms")
## Subset incomplete cases for final rounds dataframe: 
data2 <- finalRounds[finalRounds$results.manipulationCheck!="", ]
## Select only variables of interest from final rounds: 
data2 = data2 %>% select(id, batch, room, bonus, name, friends, 
                         friends_history, results.condition, results.format,results.blacklistCheck, round)
## Convert to compatible data types before merge: 
data2$batch <- unlist(data2$batch)
data2$round <- unlist(data2$round)
data2$id <- unlist(data2$id) 
data$batch <- unlist(data$batch)

## Before merge, data and data2 should have the same # of observations
## Merge columns by id, round and batch #s: 
data <- cbind(data, data2)
## Subset only observations with batch #s in complete batches 
allConditions <- data[data$batch %in% completeBatches, ]
## Convert unique names: 
data <- data[, !duplicated(colnames(data))]
```
## Conditionally assign conditions based on treatment and results column: 
```{r, echo=TRUE} 
## Messy, but robust? Verify, verify, verify people:   
## For runs with 3 rounds: 
# data <- data %>% mutate(
#   condition = case_when(
#     results.condition=='treatment' & results.format=="c(1, 2, 1)" & round==1 ~ "A", 
#     results.condition=='treatment' & results.format=="c(1, 2, 1)" & round==2 ~ "B", 
#     results.condition=='treatment' & results.format=="c(1, 2, 1)" & round==3 ~ "Ap", 
#     results.condition=='treatment' & results.format=="c(1, 1, 2)" & round==1 ~ "A", 
#     results.condition=='treatment' & results.format=="c(1, 1, 2)" & round==2 ~ "Ap", 
#     results.condition=='treatment' & results.format=="c(1, 1, 2)" & round==3 ~ "B", 
#     results.condition=='treatment' & results.format=="c(2, 1, 1)" & round==1 ~ "B", 
#     results.condition=='treatment' & results.format=="c(2, 1, 1)" & round==2 ~ "A", 
#     results.condition=='treatment' & results.format=="c(2, 1, 1)" & round==3 ~ "Ap" ,
#     results.condition=='control' & results.format=="c(1, 2, 1)" & round==1 ~ "A", 
#     results.condition=='control' & results.format=="c(1, 2, 1)" & round==2 ~ "B", 
#     results.condition=='control' & results.format=="c(1, 2, 1)" & round==3 ~ "Ap", 
#     results.condition=='control' & results.format=="c(1, 1, 2)" & round==1 ~ "A", 
#     results.condition=='control' & results.format=="c(1, 1, 2)" & round==2 ~ "Ap", 
#     results.condition=='control' & results.format=="c(1, 1, 2)" & round==3 ~ "B", 
#     results.condition=='control' & results.format=="c(2, 1, 1)" & round==1 ~ "B", 
#     results.condition=='control' & results.format=="c(2, 1, 1)" & round==2 ~ "A", 
#     results.condition=='control' & results.format=="c(2, 1, 1)" & round==3 ~ "Ap" ,
#     results.condition=='baseline' & results.format=="1:3" & round==1 ~ "A" ,
#     results.condition=='baseline' & results.format=="1:3" & round==2 ~ "B" ,
#     results.condition=='baseline' & results.format=="1:3" & round==3 ~ "C" 
#   )) 

## For runs with 4 rounds: 
data <- data %>% mutate(
  condition = case_when(
    results.format=="c(1, 1, 2, 3)" & round==1 ~ "A", 
    results.format=="c(1, 1, 2, 3)" & round==2 ~ "Ap", 
    results.format=="c(1, 1, 2, 3)" & round==3 ~ "B", 
    results.format=="c(1, 1, 2, 3)" & round==4 ~ "B", 
    results.format=="c(1, 2, 1, 3)" & round==1 ~ "A", 
    results.format=="c(1, 2, 1, 3)" & round==2 ~ "B", 
    results.format=="c(1, 2, 1, 3)" & round==3 ~ "Ap", 
    results.format=="c(1, 2, 1, 3)" & round==4 ~ "B", 
    results.format=="c(2, 1, 1, 3)" & round==1 ~ "B", 
    results.format=="c(2, 1, 1, 3)" & round==2 ~ "A", 
    results.format=="c(2, 1, 1, 3)" & round==3 ~ "Ap", 
    results.format=="c(2, 1, 1, 3)" & round==4 ~ "B", 
    results.format=="c(2, 3, 1, 1)" & round==1 ~ "B", 
    results.format=="c(2, 3, 1, 1)" & round==2 ~ "B", 
    results.format=="c(2, 3, 1, 1)" & round==3 ~ "A", 
    results.format=="c(2, 3, 1, 1)" & round==4 ~ "Ap",
    results.format=="c(2, 1, 3, 1)" & round==1 ~ "B", 
    results.format=="c(2, 1, 3, 1)" & round==2 ~ "A", 
    results.format=="c(2, 1, 3, 1)" & round==3 ~ "B", 
    results.format=="c(2, 1, 3, 1)" & round==4 ~ "Ap", 
    results.format=="c(1, 2, 3, 1)" & round==1 ~ "A", 
    results.format=="c(1, 2, 3, 1)" & round==2 ~ "B", 
    results.format=="c(1, 2, 3, 1)" & round==3 ~ "B", 
    results.format=="c(1, 2, 3, 1)" & round==4 ~ "Ap"
  )) 
```

```{r, echo=TRUE}
## Rename: 
data <- rename(data, "blacklistIndividual" = results.qFifteenCheck) 
data <- rename(data, "blacklistMeta" = results.qSixteenCheck)
## Factor for visualizations: 
levels <- c("Strongly Disagree", "Disagree", "Neutral","Agree", "Strongly Agree") 
clean <- data %>% 
  mutate_at(.vars = vars(contains("results.viabilityCheck")), funs(factor(., levels = levels))) 
clean <- clean %>% filter(results.manipulation!="") 
data$blacklistIndividual <- as.character(data$blacklistIndividual) 
data$blacklistMeta <- as.character(data$blacklistMeta) 
## Create a new dataframe that converts factors to numeric for statistical analyses:
stats <- clean %>% mutate_if(is.factor, as.numeric)
for (i in 1:nrow(stats)) {
  stats$sum[i] <- sum(stats[i,1:14])                          
} 
stats$median <- median(stats$sum)
stats$mean <- mean(stats$sum)
stats$room <- unlist(stats$room)
stats$results.condition <- unlist(stats$results.condition)
stats$results.format <- as.character(stats$results.format)
## to-do: apply function is best 
## Revalue repeat team: keep plyr b/c some weird R stuff requires library to be called directly (recode values to )
stats$blacklistMeta <-car::recode(stats$blacklistMeta,"1=0;2=1")
stats$blacklistIndividual <-car::recode(stats$blacklistIndividual,"1=0;2=1")
groupedProportion <- stats %>%
  group_by(room, batch, round, condition, results.condition, results.format) %>%  ## to-do: add group ID in storage db. 
  summarise(n=n(), mean=mean(sum), median=median(sum),prop=sum(blacklistIndividual)/n) %>%
## Filter out all teams with n=1 (i.e. a person in a one person team) 
  filter(n>1)

## Individual proportion: 
individualProportion <- stats %>% group_by(round, batch, room) %>% 
  mutate(sum=sum, mean=mean(sum), median=median(sum), n=n(),prop=sum(blacklistIndividual)/n) %>% 
  filter(n>1)
print(individualProportion)

## Table showing how many teams we've run in each condition combination:  
print(table(groupedProportion$condition, groupedProportion$results.condition)) 
```

## Probability of fracture across teams and condition combinations: 
```{r, echo=TRUE, warning=}
## Define and initialize cut-off point for fracture: 
groupedProportionFracture <- groupedProportion %>%
  group_by(results.condition, condition) %>% 
  mutate(fracture = case_when (prop<.50 ~ "0", 
                                prop>=.50~ "1"), sd=sd(fracture)) 

## Define and initialize cut-off point for fracture: 
individualProportionFracture <- individualProportion %>%
  group_by(results.condition, condition) %>% 
  mutate(fracture = case_when (prop<.50 ~ "0", 
                                prop>=.50~ "1"), sd=sd(fracture)) 

## Baseline: (we probably won't need this since we are artificially making baseline conditions)
# groupedProportionFractureBaseline <- 
#   groupedProportionFracture %>% 
# filter(results.condition=="baseline") %>% 
#   filter(id %in% condition=="A" & condition=="C")
# baselineFracture1 <- groupedProportionFractureBaseline %>% filter(condition=="A")
# baselineFracture2 <- groupedProportionFractureBaseline %>% filter(condition=="C")

# To-do: triple check if this is right:  

groupedProportionFractureBaseline <- groupedProportionFracture %>% filter(results.format=="c(1, 1, 2, 3)" | results.format=="c(1, 2, 1, 3)" | results.format=="c(2, 1, 1, 3)" | results.format=="c(2, 3, 1, 1)" | results.format=="c(2, 1, 3, 1)") %>% filter(round=="1" | round=="4") 
baselineFracture1 <- groupedProportionFractureBaseline %>% filter(round=="1")
baselineFracture2 <- groupedProportionFractureBaseline %>% filter(round=="4")
baselineFracture1$fracture1 <- baselineFracture1$fracture
baselineFracture2$fracture2 <- baselineFracture2$fracture
## To deal with unequal round 1 and round 4 # of teams: 
baselineFracture2 <- baselineFracture2 %>% semi_join(baselineFracture1, by = c("results.format", "batch"))
baselineFracture <- cbind(baselineFracture2, baselineFracture1)

## Treatment: 
groupedProportionFractureTreatment <- groupedProportionFracture %>% 
filter(results.condition=="treatment")
treatmentFracture1 <- groupedProportionFractureTreatment %>% filter(condition=="A")
treatmentFracture2 <- groupedProportionFractureTreatment %>% filter(condition=="Ap")
treatmentFracture1 <- treatmentFracture1 %>% semi_join(treatmentFracture2, by=c("results.format", "batch", "n"))
treatmentFracture <- cbind(treatmentFracture1, treatmentFracture2)

## Control:  
groupedProportionFractureControl <- groupedProportionFracture %>% 
  filter(results.condition=="control") 
controlFracture1 <- groupedProportionFractureControl %>% filter(condition=="A")
controlFracture2 <- groupedProportionFractureControl %>% filter(condition=="Ap")
controlFracture2 <- controlFracture2 %>% semi_join(controlFracture2, by=c("results.format", "batch", "condition"))
controlFracture <- cbind(controlFracture1, controlFracture2)

## Manipulation check: 
## Use individual proportion data frame b/c we're interested in looking at individuals that were in teams >n=1
teamPatterns <- "Team 1 and Team 2|Team 2 and Team 3|Team 3 and Team 4|Team 1 and Team 3|Team 1 and Team 4|Team 2 and Team 4"
individualProportion$manipulationAnswerKey <- str_extract(individualProportion$results.manipulation,teamPatterns) 

print("## WARNING: FIGURE OUT WHICH MANIPULATION COLUMN ARE THE RIGHT USER ANSWERS"): 

individualProportion$manipulationAnswers <- individualProportion$manipulation
individualProportion$results.condition = unlist(individualProportion$results.condition)
## Omit NAs and results that can't be processed: 
cleanManipulation <- individualProportion[with(individualProportion, grepl(teamPatterns, manipulationAnswers) & grepl(teamPatterns, manipulationAnswerKey)),]
## Transform into compatiable form: 
cleanManipulation$manipulationAnswers = unlist(cleanManipulation$manipulationAnswers)
```

## Section #1: Does fracture have continuity with prior measures?

## 1A: Report the % of correct guesses on the manipulation check: 
```{r}
## Subset just one observation per person (right now there are four b/c rounds)
cleanManipulation <- cleanManipulation[!duplicated(cleanManipulation$id),]

## Treatment manipulation: 
treatmentManipulation <- cleanManipulation %>%  filter(results.condition=="treatment") %>%
  filter(n==2 | n==3)
print(treatmentManipulation)

## If user manipulation answers == manipulation answer key then add 1 
treatmentManipulation$correctAnswers <- sum(ifelse(treatmentManipulation$manipulationAnswers==treatmentManipulation$manipulationAnswerKey,1,0))
## Calculate percent of correct manipulation answers for treatment: 
treatmentManipulation <- treatmentManipulation %>% mutate(percentCorrect = (correctAnswers/(nrow(treatmentManipulation))))
graphTreatment <- unique(round(treatmentManipulation$percentCorrect, 2))
print(treatmentManipulation)
print(graphTreatment)
## Control manipulation: 
controlManipulation <- cleanManipulation %>% filter(results.condition=="control") %>% 
  summarise(n=n()) %>% 
  filter(n==2 | n==3) 
print(controlManipulation)

## If user manipulation answers == manipulation answer key then add 1 
controlManipulation$correctAnswers <- sum(ifelse(controlManipulation$manipulationAnswers==controlManipulation$manipulationAnswerKey,1,0))
## Calculate percent of correct manipulation answers for control: 
controlManipulation <- controlManipulation %>% mutate(percentCorrect = (correctAnswers/(nrow(controlManipulation))))
graphControl <- unique(round(controlManipulation$percentCorrect, 2))
print(controlManipulation)
print(graphControl)

controlManipulation2 <- unique(controlManipulation$percentCorrect)*100
treatmentManipulation2 <- unique(treatmentManipulation$percentCorrect)*100
chanceManipulation <- c(25)
print(c(controlManipulation2, treatmentManipulation2, chanceManipulation))
```

## Plot for manipulation check results: 
```{r}
dat <- data.frame(manipulationCheck=factor(c("Masked","Unmasked"), levels=c("Masked","Unmasked")),
                  manipulation = c(graphTreatment, graphControl))

p <- ggplot(data=dat, aes(x=manipulationCheck, y=manipulation)) +
  geom_bar(stat="identity", fill="steelblue")+
  geom_text(aes(label=manipulation), vjust=1.6, color="white", size=3.5)+
  geom_hline(yintercept=0.33, size=0.4, color="black") + 
  theme_minimal() + labs(subtitle="Comparison between manipulation check results in masked and unmasked conditions", 
       x="Condition",
       y="Percentage of participants who selected the right answer on our manipulation check")
p
```

## 1B: Proportion test comparing treatment manipulation percent correct with chance: 
```{r}
## Proportion test with treatment and chance: 
treatmentChanceManipulation <- prop.test(x = c(chanceManipulation, treatmentManipulation2), n = c(100, 100))
print(treatmentChanceManipulation)

## Proportion test with treatment and control: 
treatmentControlManipulation <- prop.test(x = c(controlManipulation2, chanceManipulation), n = c(100, 100))
print(treatmentControlManipulation)
```

## 1C: Logistic regression predicting binary fracture outcome from viability scales: 
```{r}
## Simple logistic regression: we will fit a logistic regression model in order to predict 
## the probability of fracture based on a team's average viability sum: 
model1 <- glm(fracture ~ mean, family = "binomial", data = groupedProportionFracture)
stargazer(model1, title="Results", align=TRUE)
summary(model1)
print(model1)
```

## Test predictive power of logistic regression: 
```{r echo=TRUE, eval=FALSE}
## From output we see that a one unit decrease in mean viability score is associated with a decreasein the log odds of fracture by 0.26 units. 

## Check predictive power: 

## Split data into 60% training and 40% testing data sets to test how well the model performs 
set.seed(123)
groupedProportionFracture$fracture <- as.numeric(groupedProportionFracture$fracture) 
sample <- sample(c(TRUE, FALSE), nrow(groupedProportionFracture), replace = T, prob = c(0.6,0.4))
train <- groupedProportionFracture[sample, ]
test <- groupedProportionFracture[!sample, ]

model2 <- glm(fracture ~ mean, family = "binomial", data = train)
stargazer(model2, title="Training Results", align=TRUE)
summary(model2)
print(model2)
## To assess the linear regression deviance, look at deviance in summary output, if 
## deviance == sum of sqaures in linear regression, null deviance == difference between. a model with only the intercept ("no mean predictors") and the a saturated model a model with a theoretically perfect fit. Model deviance (residual deviance) should be lower (i.e. small values == better fit). 

print(tidy(model1)) 
print(tidy(model2))
## Coefficient estimtes from log regression characterize relationship between the predictor and 
## response variable on a log-odds scale, so binary increase from no fracture - fracture can be interpreted as associated with a decrease in mean viability sum. 

## More coefficient output: measure the confidence intervals and accuracy of the coefficent: 
confint(model1)

## Making predictions: 
## What is the probability of fracture given the following team mean viability scores: for example purposes: 55 and 65: 

predict(model2, data.frame(mean = c(55, 65)), type = "response")

## From the output, we can see that the probability of fracture decreases from 0.31% to 0.03% when mean viability sum increases from 55 to 65. 

## Another example, with means 45 and 60: 

predict(model2, data.frame(mean = c(40, 60)), type = "response")

## From the output, we can see that the probability of fracture decreases from 0.96% to 0.10% when mean viability sum increases from 40 to 60. 

## Model evaluation & diagnostics: 
## How well does the model fit the data? And how accurate are the predictions on an out-of-sample data set?

## Residul assessment: 
model1_data <- augment(model1) %>% 
  mutate(index = 1:n())

ggplot(model1_data, aes(index, .std.resid, color = mean)) + 
  geom_point(alpha = .5) +
  geom_ref_line(h = 3)

## Validation of predicted values: 
## How well does the model perform when predicting the target variable on out-of-sample observations? 

test.predicted.m1 <- predict(model1, newdata = test, type = "response")

## Classification performance for each model on the test data. Output gives us a list of true / false positives: 

list(
  model1 = table(test$mean, test.predicted.m1 > 0.5) %>% prop.table() %>% round(3)) 

table(test$mean, test.predicted.m1 > 0.5)
```

## Logistic regression on individual score: 
```{r, eval=FALSE}
individualProportionFractureTreatment <- individualProportionFracture %>% 
filter(results.condition=="treatment")
individualTreatmentFracture1 <- individualProportionFractureTreatment %>% filter(condition=="A")
individualTreatmentFracture2 <- individualProportionFractureTreatment %>% filter(condition=="Ap")
individualTreatmentFracture <- cbind(individualTreatmentFracture1, individualTreatmentFracture2)

## Need to finish this 

```

## 1D: Graph of fracture/no fracture vs. mean/stdev viability scale

# Boxplot: mean viability survey scores + fracture value (group level + individual level)
```{r}
g <- ggplot(groupedProportionFracture, aes(factor(fracture), mean)) 
g + geom_boxplot(varwidth=T, fill="steelblue") + 
  labs(subtitle="Boxplot correlation between teams' mean viability and binary fracture score", 
       x="",
       y="Teams' mean viability survey score (range 14-70)") +
 scale_x_discrete(labels=c("0" = "Keep this team", "1" = "Do not keep this team")) + theme_grey()


g <- ggplot(groupedProportionFracture, aes(factor(fracture), mean)) 
g + geom_boxplot(varwidth=T, fill="steelblue") + 
  labs(subtitle="Boxplot correlation between individual mean viability and binary fracture scores", 
       x="",
       y="Teams' mean viability survey score (range 14-70)") +
 scale_x_discrete(labels=c("0" = "Keep this team", "1" = "Do not keep this team")) + theme_grey()
```

# Correlation scatterplot: mean viability survey scores + fracture value (group level + individual level)
```{r}
## Grouped fracture correlation: 
ggplot(data=groupedProportionFracture, aes(fracture, mean)) + 
   geom_point() +
  stat_smooth(method = "lm", col = "red") + labs(title="Scatterplot correlation between teams' mean viability and binary fracture scores", y="Teams' mean viability survey score (range 14-70) ", x="Teams' binary fracture score") +  theme_grey() + 
scale_x_discrete(labels=c("0" = "Keep this team", "1" = "Do not keep this team"))

## Individual fracture correlation: 
ggplot(data=individualProportionFracture, aes(fracture, mean)) + 
   geom_point() +
  stat_smooth(method = "lm", col = "red") + labs(subtitle="Scatterplot correlation between individuals' mean viability and binary fracture scores", y="Individual mean viability survey scores (range 14-70 ", x="Individual binary fracture score") +  theme_grey() + 
scale_x_discrete(labels=c("0" = "Keep this team", "1" = "Do not keep this team"))

## Grouped fracture proportion correlation: 
ggplot(data=individualProportionFracture, aes(prop, mean)) + 
   geom_point() +
  stat_smooth(method = "lm", col = "red") + labs(subtitle="Scatterplot correlation between teams' mean viability and team fracture proportion", y="Individual mean viability survey scores (range 14-70 ", x="Teams' fracture proportion") +  theme_grey() + 
scale_x_continuous(labels=c("0" = "Keep this team", "0.40", "0.60", "0.80" ,"1.00" = "Do not keep this team"))
```

# Group by and summarise fracture percentage by condition + plot for percentages:
```{r}
resultsPercent <- groupedProportionFracture %>% group_by(results.condition) %>% summarise(n=n(), fracture=sum(fracture), percent=fracture/n) %>% filter(results.condition=="control" | results.condition=="treatment")
dat <- data.frame(conditionFracturePercent= factor(c("Unmasked","Masked"), levels=c("Unmasked","Masked")),
                  fractureTotal = c(resultsPercent$percent))
dat$fractureTotal <- round(dat$fractureTotal, 3)

p <- ggplot(data=dat, aes(x=conditionFracturePercent, y=fractureTotal)) +
  geom_bar(stat="identity", fill="steelblue")+
  geom_text(aes(label=fractureTotal), vjust=1.6, color="white", size=3.5)+
  theme_grey() + labs(title="Frequency of total fracture percents across three rounds between unmasked and masked conditions", 
       x="",
       y="Frequency of fracture percentage per condition") 
p
```

# Plot of total fracture percentages across four rounds all conditions: 
```{r}
resultsRound <- groupedProportionFracture %>% group_by(round) %>% summarise(n=n(), fracture=sum(fracture), percent=fracture/n) 

dat <- data.frame(roundFracturePercent= factor(c("Round 1","Round 2", "Round 3", "Round 4"), levels=c("Round 1","Round 2", "Round 3", "Round 4")),
                  fractureTotal = c(resultsRound$percent))
dat$fractureTotal <- round(dat$fractureTotal, 3)

p <- ggplot(data=dat, aes(x=roundFracturePercent, y=fractureTotal)) +
  geom_bar(stat="identity", fill="steelblue")+
  geom_text(aes(label=fractureTotal), vjust=1.6, color="white", size=3.5)+
  theme_grey() + labs(subtitle="Percentage of total fracture across three rounds for all conditions", 
       x="",
       y="Percent of fracture per round") 
p
```

# Frequency of fracture proportions per condition: 
```{r}
ggplot(groupedProportionFracture, aes(x = factor(fracture))) + 
    geom_bar(fill="steel blue", aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent)  + 
  scale_x_discrete(labels=c("0"="Keep this team", "1"="Do not keep this team")) + labs(title="Percent of binary team fracture value scores across all conditions", y="Percent of fracture value", x="Binary team fracture score") +  facet_grid(.~results.condition) + theme_gray()
```

# Frequency of fracture proportions per round: 
```{r}
gplot(groupedProportionFracture, aes(x = prop)) + 
    geom_bar(fill="steel blue", aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent)  + scale_x_continuous()+  labs(title="Percent of binary team fracture value scores across all conditions", y="Percent of fracture value", x="Binary team fracture score") +  facet_grid(.~round) + theme_gray()
```

# Frequency of mean viability scores per condition: 
```{r}
ggplot(groupedProportionFracture, aes(x = factor(mean))) + 
    geom_bar(fill="steel blue", aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent)  + 
  scale_x_discrete(labels=c("0"="Keep this team", "1"="Do not keep this team")) + labs(title="Percent of binary team fracture value scores across all conditions", y="Percent of fracture value", x="Binary team fracture score") +  facet_grid(.~results.condition) + theme_gray()
```

## Section #2: How often does fracture occur?

# 2A: P(binary fracture) histogram of fracture proportion (by team)
```{r}
ggplot(data=groupedProportionFracture, aes(groupedProportionFracture$fracture)) + 
  geom_histogram(breaks=seq(0, 1, by=0.20), 
                 col="red", 
                 fill="green", 
                 alpha=.2) + labs(title="Fracture rate across all conditions", 
                                  x="Teams' binary fracture value", y="Count") +
  geom_errorbar(width=.5, aes(ymin=fracture-sd, ymax=fracture-sd), colour="red") 
```

## CHI squared tests: 
```{r}
library(MASS)     
## Test if whether fracture is independent of condition (i.e. baseline, control & treatment) at .05 significance level: 
chi = table(groupedProportionFracture$results.condition, groupedProportionFracture$fracture)  
chi
print(chisq.test(chi)) 
```

## 2B: What's the overall % of fracturing the second time? (by condition)
```{r}
## Filtering second time only: 
groupedProportionFracture$fracture <- as.numeric(groupedProportionFracture$fracture)
groupedProportionFractureOverall <- groupedProportionFracture %>% 
      mutate(overallPercent = sum(as.numeric(fracture))) %>% 
      summarise(n=n(), overallPercent=unique(overallPercent/n))  

mean(groupedProportionFractureOverall$overallPercent)

groupedProportionFractureB <- groupedProportionFracture %>% 
      filter(condition=="B") %>% 
      mutate(overallPercent = sum(as.numeric(fracture))) %>% 
      summarise(n=n(), overallPercent=unique(overallPercent/n))  
print(groupedProportionFractureB) 
mean(groupedProportionFractureB$overallPercent)

## To-do: review below code, worried it's incorrect: 

groupedProportionFractureSecond <- groupedProportionFracture %>% group_by(results.condition) %>% 
      filter(condition=="Ap") %>% 
      mutate(overallPercent = sum(as.numeric(fracture))) %>% 
      summarise(n=n(), overallPercent=unique(overallPercent)/n) 
print(groupedProportionFractureSecond)

## For baseline theoretical distribution: (to-do: look over this, worried also that it's wrong)

groupedProportionFractureSecondBase <- groupedProportionFractureBaseline %>%
      filter(condition=="B") %>% 
      summarise(n=n(), overallPercent=sum(as.numeric(fracture))/n) 

print(groupedProportionFractureSecondBase$overallPercent)
```

## Proportion tests for total fracture change: 
```{r}
## Set-up separate groups for proportion tests to answer: does unmasked fracture more/less than masked, and more/less than new pairs? 

## Is the proportion of fracture in the second round significantly different in the two conditions (i.e. treatment + baseline) 
treatmentvsBaselineChange <- c(48, 49)
propFractureChangeTreatmentvsBase <- prop.test(x = c(treatmentvsBaselineChange), n = c(100, 100))
print(propFractureChangeTreatmentvsBase) 

## Is the proportion of fracture in the second round significantly different in the two conditions (i.e. control + baseline) 
controlvsBaselineChange <- c(40, 49)
propFractureChangeControlvsBase <- prop.test(x = c(controlvsBaselineChange), n = c(100, 100))
print(propFractureChangeControlvsBase)
```

## Section 3: How consistent is fracture? 
## 3A: calculating the conditional probabilities of fracture for each condition: 
```{r}
## If fractured the first time, what's the % of fracturing the second time? look at 1 and Ap combination for % in second time: 

## Compare both treatment and control with baseline as theoretical distribution: 

## Conditional probability for masked: 
# of groups who fractured 1 and 2
treatmentFracture12 <- sum(ifelse(treatmentFracture1$fracture=="1" & treatmentFracture2$fracture=="1",1,0))/nrow(treatmentFracture)
# of groups who fractured only 1
treatmentFractureOnly1 <- sum(ifelse(treatmentFracture1$fracture=="1" & treatmentFracture2$fracture=="0",1,0))/nrow(treatmentFracture) 
# of groups who fractured only 2
treatmentFractureOnly2 <- sum(ifelse(treatmentFracture1$fracture=="0" & treatmentFracture2$fracture=="1",1,0))/nrow(treatmentFracture)
# of groups who fractured never        
treatmentFractureNever <- sum(ifelse(treatmentFracture1$fracture=="0" & treatmentFracture2$fracture=="0",1,0))/nrow(treatmentFracture)
conditionalProbTreatment <- matrix(c(treatmentFracture12, treatmentFractureOnly1, treatmentFractureOnly2, treatmentFractureNever),ncol=2,byrow=TRUE)
colnames(conditionalProbTreatment) <- c("Ap frac","Ap no frac") 
rownames(conditionalProbTreatment) <- c("A frac","A no frac")
conditionalProbTreatment <- as.table(conditionalProbTreatment)
print(conditionalProbTreatment) 
```

```{r}
## Conditional proability for unmasked: 
# of groups who fractured 1 and 2
controlFracture12 <- sum(ifelse(controlFracture1$fracture=="1" & controlFracture2$fracture=="1",1,0))/nrow(controlFracture)
# of groups who fractured only 1
controlFractureOnly1 <- sum(ifelse(controlFracture1$fracture=="1" & controlFracture2$fracture=="0",1,0))/nrow(controlFracture) 
# of groups who fractured only 2
controlFractureOnly2 <- sum(ifelse(controlFracture1$fracture=="0" & controlFracture2$fracture=="1",1,0))/nrow(controlFracture)
# of groups who fractured never        
controlFractureNever <- sum(ifelse(controlFracture1$fracture=="0" & controlFracture2$fracture=="0",1,0))/nrow(controlFracture)
conditionalProbControl <- matrix(c(controlFracture12, controlFractureOnly1, controlFractureOnly2, controlFractureNever),ncol=2,byrow=TRUE)
colnames(conditionalProbControl) <- c("Ap frac","Ap no frac") 
rownames(conditionalProbControl) <- c("A frac","A no frac")
print(conditionalProbControl) 
```

```{r}
## Conditional proability for baseline
# of groups who fractured 1 and 2
baselineFracture12 <- sum(ifelse(baselineFracture1$fracture=="1" & baselineFracture2$fracture=="1",1,0))/nrow(baselineFracture)
# of groups who fractured only 1
baselineFractureOnly1 <- sum(ifelse(baselineFracture1$fracture=="1" & baselineFracture2$fracture=="0",1,0))/nrow(baselineFracture)
# of groups who fractured only 2
baselineFractureOnly2 <- sum(ifelse(baselineFracture1$fracture=="0" & baselineFracture2$fracture=="1",1,0))/nrow(baselineFracture)
# of groups who fractured never        
baselineFractureNever <- sum(ifelse(baselineFracture1$fracture=="0" & baselineFracture2$fracture=="0",1,0))/nrow(baselineFracture)
conditionalProbBaseline <- matrix(c(baselineFracture12, baselineFractureOnly1, baselineFractureOnly2, baselineFractureNever),ncol=2,byrow=TRUE)
colnames(conditionalProbBaseline) <- c("Ap frac","Ap no frac") 
rownames(conditionalProbBaseline) <- c("A frac","A no frac")
conditionalProbBaseline
```

```{r}
# kable(conditionalProbBaseline, "latex", caption = "Demo table", booktabs = T) %>%
# kable_styling(latex_options = c("striped", "hold_position"))
```

## 3B: Now investigating the big result: switch %: what's the % of pairs flipping their decisions?

```{r}
## Convert format before merge: *this can be simplified*: 
treatmentFracture2$fracture <- as.numeric(treatmentFracture2$fracture) 
treatmentFracture1$fracture <- as.numeric(treatmentFracture1$fracture) 
treatmentFracture$absFracture <- abs(treatmentFracture2$fracture-treatmentFracture1$fracture)

controlFracture1$fracture <- as.numeric(controlFracture1$fracture)
controlFracture2$fracture <- as.numeric(controlFracture2$fracture)
controlFracture$absFracture <- abs(controlFracture2$fracture-controlFracture1$fracture)

baselineFracture$fracture1 <- as.numeric(baselineFracture$fracture1) 
baselineFracture$fracture2 <- as.numeric(baselineFracture$fracture2) 
baselineFracture$absFracture <- abs(baselineFracture$fracture1-baselineFracture$fracture2)

## Results here seem fishy? Triple check my code for abs/sum? 

treatmentFractureAbsSum <- sum(treatmentFracture$absFracture) 
print(treatmentFractureAbsSum)
controlFractureAbsSum <- sum(controlFracture$absFracture)
print(controlFractureAbsSum)
baselineFractureAbsSum <- sum(baselineFracture$absFracture) 
print(baselineFractureAbsSum)

## Don't we want a proportion test here before adding / trying chi-squared? 

normalizedTreatmentChange <- treatmentFractureAbsSum/nrow(treatmentFracture)
normalizedControlChange <- controlFractureAbsSum/nrow(controlFracture)
normalizedBaselineChange <- round(baselineFractureAbsSum/nrow(baselineFracture), 2)

treatmentAbsChange=c(normalizedTreatmentChange)*100
controlAbsChange=c(normalizedControlChange)*100
baselineAbsChange=c(normalizedBaselineChange)*100 

## Proportion test: 
prop.test(x = c(treatmentAbsChange, controlAbsChange), n = c(100, 100))

## Chi goodness of fit: 
## Using baseline as theoretical probability distribution 
## Treatment: 
chisq.test(treatmentAbsChange, p = baselineAbsChange/sum(baselineAbsChange)) 
chisq.test(treatmentAbsChange, controlAbsChange, p=baselineAbsChange)
## Control:
chisq.test(controlAbsChange,p=baselineAbsChange)
```

## Visualizing change: 
```{r}
## Visualize differences: 
dat <- data.frame(NormalizedAbsoluteFractureChange= factor(c("Masked","Unmasked"), levels=c("Masked","Baseline","Unmasked")),
                  fractureValueSwitch = c(normalizedTreatmentChange, normalizedControlChange))

dat$sd <- sd(dat$fractureValueSwitch)
p <- ggplot(data=dat, aes(x=NormalizedAbsoluteFractureChange, y=fractureValueSwitch)) +
  geom_bar(stat="identity", fill="steelblue")+
  geom_text(aes(label=fractureValueSwitch), vjust=1.6, color="white", size=3.5)+
  theme_grey() + labs(subtitle="Normalized absolute value change in team fracture value", 
       x="",
       y="Percent of total fracture value change")
p
```

## Visualizing meta-cognition differences: 
```{r}
ggplot(individualProportionFracture, aes(x = factor(blacklistIndividual))) + 
    geom_bar(fill="steel blue", aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent)  + 
  scale_x_discrete(labels=c("0"="Keep this team", "1"="Do not keep this team")) + labs(title="Percent of individual blacklist binary answers across all conditions", y="Percent of fracture value", x="Binary individual fracture answer") +  facet_grid(.~results.condition) + theme_gray()

ggplot(individualProportionFracture, aes(x = factor(blacklistMeta))) + 
    geom_bar(fill="steel blue", aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent)  + 
  scale_x_discrete(labels=c("0"="Keep this team", "1"="Do not keep this team")) + labs(title="Percent of meta blacklist binary answers across all conditions", y="Percent of fracture value", x="Binary meta  fracture answer") +  facet_grid(.~results.condition) + theme_gray()
```

```{r}
individualProportion$equalAnswers <- sum(ifelse(individualProportion$blacklistIndividual==individualProportion$blacklistMeta,1,0))
## Calculate percent of correct manipulation answers for treatment: 
individualProportion <- individualProportion %>% mutate(percentCorrect = (equalAnswers/(nrow(individualProportion))))
graphTreatment <- unique(round(individualProportion$percentCorrect, 2))

ggplot(individualProportionFracture, aes(x = factor(blacklistIndividual))) + 
    geom_bar(fill="steel blue", aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent)  + 
  scale_x_discrete(labels=c("0"="Keep this team", "1"="Do not keep this team")) + labs(title="Percent of individual blacklist binary answers across all conditions", y="Percent of fracture value", x="Binary individual fracture answer") +  facet_grid(.~results.condition) + theme_gray()

```




