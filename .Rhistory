}
## Assessing parametric normality:
hist(experiment2$sum,xlab="Sum of scores",main="")
## From the histogram above we can “unofficially”conclude that our data is relitively Normal,
## hance we are somewhat justified in using parametric statistical methodology.
## What is this saying: difference between sum of scores (high vs. low) and continue working
### with team Q.
boxplot(sum~nominalQ15,data=merged,names=c("Continue working with team",
"Stop working with team"))
boxplot(sum~blacklist,data=merged,names=c("Blacklist Team 1",
"Blacklist Team 2", "Indifferent"))
t.test(sum~nominalQ15, data=merged)
t.test(sum~blacklist, data=merged)
## First use a boxplot for visualization:
boxplot(sum~nominalQ15,data=merged,names=c("Continue working with team",
"Stop working with team"))
boxplot(sum~blacklist,data=merged,names=c("Blacklist Team 1",
"Blacklist Team 2", "Indifferent"))
t.test(sum~nominalQ15, data=merged)
t.test(sum~blacklist, data=merged)
## results indicate no, not a significant difference.
## breakdown by room & round:
roomAround1<- experiment2 %>%
filter(round=="1", room=="A")
roomAround2<- experiment2 %>%
filter(round=="2", room=="A")
roomBround1<- experiment2 %>%
filter(round=="1", room=="B")
roomBround2<- experiment2 %>%
filter(round=="2", room=="B")
## t-tests:
## round 1, room a:
t.test(sum~nominalQ15, data=roomAround1)
## round 1, room b:
t.test(sum~nominalQ15, data=roomBround1)
## round 2, room a:
t.test(sum~nominalQ15, data=roomAround2)
## round 2, room b:
t.test(sum~nominalQ15, data=roomBround2)
## Anova for survey questions, starting with repeat team question with sum of scores:
anova(lm(sum~RTQ,data=experiment2))
## Blacklist importing, cleaning & merging:
input2 = '[{"userID":"qL44K5kHvqZwHuzcAAAA","name":"niceWolf","midSurvey":"blacklist-q1=1","batch":1532028198071,"_id":"BGXqnkNyGqqpHP2c"}
,{"userID":"1pob6EHCHwzLa7nUAAAB","name":"culturedCat","midSurvey":"blacklist-q1=2","batch":1532028198071,"_id":"ELtcSJgRysGlBB77"}
,{"userID":"FGzkFbpp8ejWVSm0AAAC","name":"niceRabbit","midSurvey":"blacklist-q1=2","batch":1532028198071,"_id":"V37TWQFeRT0CwIf6"}
,{"userID":"-2emRdtAMYWaULymAAAD","name":"conventionalDeer","midSurvey":"blacklist-q1=2","batch":1532028198071,"_id":"uXGDrroAYDrKaIVh"}]'
blacklist = fromJSON(input2, simplifyDataFrame = TRUE)
blacklist <- as.data.frame(blacklist)
for (i in 1:length(blacklist$midSurvey)) {
blacklist$blacklist[i] <- substr(blacklist$midSurvey[i], 14, 20)
}
## Factoring for stats analysis
levels3 <- c(1:3)
blacklist <- blacklist %>%
mutate_at(.vars = vars(blacklist), funs(factor(., levels = levels3)))
## Factor summary / basic descriptive stats for likert :
merged <- merge(experiment2,blacklist,by="name")
## is there a significant difference between sum of survey question // blacklist (yes=1) (no=2) (don't care=3)
t.test(sum~blacklist, data=mergetest)
studentModel <- train(sum~blacklist, data=mergetest, method = "knn")
## analysis results:
## Scale validity
## Exploratory factor analysis introduction:
## Determine ## of factors;
mydata <- experiment2[,23:36]
ev <- eigen(cor(mydata)) # get eigenvalues
ap <- parallel(subject=nrow(mydata),var=ncol(mydata),
rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
## Optimal coordinates: n=1
#calculate the correlation matrix
corMat <- cor(mydata)
#display the correlation matrix
corMat
#use fa() to conduct an oblique principal-axis exploratory factor analysis
#save the solution to an R variable
solution <- fa(r = corMat, nfactors = 1, rotate = "oblimin", fm = "pa")
#display the solution output
solution
pca2 <- principal(data.matrix(mydata))
print(pca2)
KMO(data.matrix(experiment2[,8:12]))
## Calculating the number of factors
scale <- experiment2[, 23:36]
parallel <- fa.parallel(scale, fm = 'minres', fa = 'fa')
## Results show the maximum number of factors we can consider.
## Factor analysis now that we know # of factors:
## Using oblimin because we believe we believe that there is correlation in the factors.
threefactor <- fa(scale,nfactors = 3,rotate = "oblimin",fm="minres")
print(threefactor)
## Output shows loadings and factors
## Next, consider the loadings more than 0.3 and not loading on more than one factor:
print(threefactor$loadings,cutoff = 0.3)
## Based on this output we will consider X factors:
fourfactor <- fa(mydata,nfactors = 4,rotate = "oblimin",fm="minres")
print(fourfactor$loadings,cutoff = 0.3)
my_scale <- Scale(mydata,reverse=FALSE, col_names=c(1:14), items=mydata)
my_scale_pr <- PreProc(my_scale)
my_scale_it <- ItemAnalysis(my_scale_pr)
my_table <- ReportTable(my_scale_it)
## Suggestions for finding the right "test" for a null hypothesis of no differences
## in the responses between courses are not generally helpful. Significant can be
## misinterpreted; we need to base our findings not just on p-value, but also
## effect size and sig confidence intervals. It is also vital to provide a clear
## visualization of results that be quickly scanne and interpreted.
## Chi-Squared Test:
## One way to deal with "marmite" issue into binary classes and look at the number
## of responses falling into each category.
install.packages("corrr")
library(corrr)
## Average inter-item correlation: correlations between all items, averaged:
mydata %>% correlate()
class(nominalQ1)
inter_item <- mydata %>% correlate() %>% colMeans(na.rm = TRUE)
inter_item <- mydata %>% correlate()
mean(inter_item, na.rm=TRUE)
data.frame(inter_item) %>%
ggplot(aes(x = inter_item)) +
geom_histogram(bins = 10, alpha = .5) +
geom_vline(xintercept = mean(inter_item), color = "red") +
xlab("Mean inter-item correlation") +
theme_bw()
parallel <- fa.parallel(experiment2, fm = 'minres', fa = 'fa')
Results show the maximum number of factors we can consider.
## Factor analysis now that we know # of factors:
## Using oblimin because we believe we believe that there is correlation in the factors.
threefactor <- fa(data,nfactors = 3,rotate = "oblimin",fm="minres")
print(threefactor)
## Output shows loadings and factors
## Next, consider the loadings more than 0.3 and not loading on more than one factor:
print(threefactor$loadings,cutoff = 0.3)
## Based on this output we will consider X factors:
fourfactor <- fa(data,nfactors = 4,rotate = "oblimin",fm="minres")
print(fourfactor$loadings,cutoff = 0.3)
library(stats)
fit.2 <- factanal(mydata,factors=2,rotation="varimax")
n.factors <- 2
fit <- factanal(mydata,
n.factors,                # number of factors to extract
scores=c("regression"),
rotation="none")
print(fit, digits=2, cutoff=.3, sort=TRUE)
wilcox.test(merged$sum, merged$blacklist,Paired=TRUE, exact=FALSE)
wilcox.test(sum~room,data=merged)
kruskal.test(sum~round,data=merged)
merged$blacklist<- as.numeric(merged$blacklist)
wilcox.test(merged$sum, merged$blacklist, alternative = "two.sided")
mod<-polr(sum~blacklist + nominalQ15, data= merged,Hess=T)
summary(mod)
polr(formula = sum ~ blacklist + nominalQ15, data = merged, Hess = T)
coeffs <- coef(summary(mod))
p <- pnorm(abs(coeffs[, "t value"]), lower.tail = FALSE) * 2
cbind(coeffs, "p value" = round(p,3))
install.packages(c("psych", "xtable", "GPArotation", "tidyverse", "purrr", "dplyr", "jsonlite", "likert", "lavaan", "dplyr", "stringr", "ggplot2", "caret", "nFactors", "GPArotation", "Scale"))
install.packages("MASS")
library(GPArotation)
out <- factanal(covmat=cor(experiment3, use="complete.obs" ), factors=5, rotation="varimax" )
corMatrix <- cor(experiment3, use="complete.obs" )
data(bfi)
out <- factanal( covmat=cor( bfi, use="complete.obs" ), factors=5, rotation="varimax" )
class(bfi)
bfi
experiment3
experiment2
data(bfi)
corMatrix <- cor(experiment2, use="complete.obs" )
experimentfactor <- experiment2[,8:21]
experimentfactor
experimentfactor <- experiment2[,23:36]
experimentfactor
corMatrix <- cor(experimentfactor, use="complete.obs" )
corMatrix <- cor(experimentfactor, use="complete.obs" )
out <- fa(r=corMatrix, factors=5 )
print(out$loadings, cutoff=0.3 )
fa.diagram(out)
parallel<-fa.parallel(experiment2, fm='minres', fa='fa')
parallel<-fa.parallel(experimentfactor, fm='minres', fa='fa')
threefactor <- fa(experimentfactor,nfactors = 1,rotate = "oblimin",fm="minres")
parallel<-fa.parallel(experimentfactor, fm='minres', fa='fa')
threefactor <- fa(experimentfactor,nfactors = 1,rotate = "oblimin",fm="minres")
print(threefactor)
print(threefactor$loadings,cutoff = 0.3)
threefactor <- fa(experimentfactor,nfactors = 3,rotate = "oblimin",fm="minres")
print(threefactor)
fourfactor <- fa(experimentfactor,nfactors = 4,rotate = "oblimin",fm="minres")
fa.diagram(fourfactor)
experimentfactor <- experiment2[,23:36]
## Finding out the right number of factor to select for factor analysis.
## We will do this via parallel analysis
parallel<-fa.parallel(experimentfactor, fm='minres', fa='fa')
threefactor <- fa(experimentfactor,nfactors = 3,rotate = "oblimin",fm="minres")
print(threefactor)
threefactor <- fa(experimentfactor,nfactors = 1,rotate = "oblimin",fm="minres")
print(threefactor)
## Finding out the right number of factor to select for factor analysis.
## We will do this via parallel analysis
parallel<-fa.parallel(experimentfactor, fm='minres', fa='fa')
threefactor <- fa(experimentfactor,nfactors = 1,rotate = "oblimin",fm="minres")
input = '[{"userID":"FMok7RfF8Ir6cpj_AAAD","room":"A","name":"youngHorse","round":1,"midSurvey":["1=Neutral","2=Neutral","3=Strongly+Disagree","4=Strongly+Disagree","5=Strongly+Disagree","6=Strongly+Disagree","7=Strongly+Disagree","8=Strongly+Disagree","9=Strongly+Disagree","10=Strongly+Disagree","11=Strongly+Disagree","12=Strongly+Disagree","13=Strongly+Disagree","14=Strongly+Disagree","15=No"],"batch":1532472865089,"_id":"ubgZ45JFCr2ACS9l"}
,{"userID":"RWJcit56VhSfCRAtAAAE","room":"B","name":"littlePony","round":1,"midSurvey":["1=Neutral","2=Strongly+Disagree","3=Disagree","4=Disagree","5=Neutral","6=Neutral","7=Neutral","8=Neutral","9=Disagree","10=Disagree","11=Disagree","12=Disagree","13=Disagree","14=Disagree","15=No"],"batch":1532472865089,"_id":"oNbfceB7Baaxb05q"}
,{"userID":"ibOWTvftXMLZaFadAAAL","room":"B","name":"spryBison","round":1,"midSurvey":["1=Agree","2=Neutral","3=Agree","4=Agree","5=Neutral","6=Agree","7=Neutral","8=Neutral","9=Agree","10=Neutral","11=Agree","12=Neutral","13=Disagree","14=Neutral","15=Yes"],"batch":1532472865089,"_id":"uyWItNKNkggQ4hz3"}
,{"userID":"8tVCBI2eCkVhxzVPAAAK","room":"A","name":"littleHorse","round":1,"midSurvey":["1=Strongly+Disagree","2=Neutral","3=Agree","4=Neutral","5=Neutral","6=Agree","7=Neutral","8=Agree","9=Neutral","10=Agree","11=Strongly+Agree","12=Agree","13=Neutral","14=Neutral","15=Yes"],"batch":1532472865089,"_id":"0MH4wqYOYJfZHZjd"}'
experiment = fromJSON(input, simplifyDataFrame = TRUE)
experiment <- as.data.frame(experiment)
input = '[{"userID":"FMok7RfF8Ir6cpj_AAAD","room":"A","name":"youngHorse","round":1,"midSurvey":["1=Neutral","2=Neutral","3=Strongly+Disagree","4=Strongly+Disagree","5=Strongly+Disagree","6=Strongly+Disagree","7=Strongly+Disagree","8=Strongly+Disagree","9=Strongly+Disagree","10=Strongly+Disagree","11=Strongly+Disagree","12=Strongly+Disagree","13=Strongly+Disagree","14=Strongly+Disagree","15=No"],"batch":1532472865089,"_id":"ubgZ45JFCr2ACS9l"}
,{"userID":"RWJcit56VhSfCRAtAAAE","room":"B","name":"littlePony","round":1,"midSurvey":["1=Neutral","2=Strongly+Disagree","3=Disagree","4=Disagree","5=Neutral","6=Neutral","7=Neutral","8=Neutral","9=Disagree","10=Disagree","11=Disagree","12=Disagree","13=Disagree","14=Disagree","15=No"],"batch":1532472865089,"_id":"oNbfceB7Baaxb05q"}
,{"userID":"ibOWTvftXMLZaFadAAAL","room":"B","name":"spryBison","round":1,"midSurvey":["1=Agree","2=Neutral","3=Agree","4=Agree","5=Neutral","6=Agree","7=Neutral","8=Neutral","9=Agree","10=Neutral","11=Agree","12=Neutral","13=Disagree","14=Neutral","15=Yes"],"batch":1532472865089,"_id":"uyWItNKNkggQ4hz3"}
,{"userID":"8tVCBI2eCkVhxzVPAAAK","room":"A","name":"littleHorse","round":1,"midSurvey":["1=Strongly+Disagree","2=Neutral","3=Agree","4=Neutral","5=Neutral","6=Agree","7=Neutral","8=Agree","9=Neutral","10=Agree","11=Strongly+Agree","12=Agree","13=Neutral","14=Neutral","15=Yes"],"batch":1532472865089,"_id":"0MH4wqYOYJfZHZjd"}]'
experiment = fromJSON(input, simplifyDataFrame = TRUE)
experiment <- as.data.frame(experiment)
for (i in 1:length(experiment$midSurvey)) {
experiment$Q1[i] <- substr(experiment$midSurvey[[i]][1], 3, 20)
experiment$Q2[i] <- substr(experiment$midSurvey[[i]][2], 3, 20)
experiment$Q3[i] <- substr(experiment$midSurvey[[i]][3], 3, 20)
experiment$Q4[i] <- substr(experiment$midSurvey[[i]][4], 3, 20)
experiment$Q5[i] <- substr(experiment$midSurvey[[i]][5], 3, 20)
experiment$Q6[i] <- substr(experiment$midSurvey[[i]][6], 3, 20)
experiment$Q7[i] <- substr(experiment$midSurvey[[i]][7], 3, 20)
experiment$Q8[i] <- substr(experiment$midSurvey[[i]][8], 3, 20)
experiment$Q9[i] <- substr(experiment$midSurvey[[i]][9], 3, 20)
experiment$Q10[i] <- substr(experiment$midSurvey[[i]][10], 4, 20)
experiment$Q11[i] <- substr(experiment$midSurvey[[i]][11], 4, 20)
experiment$Q12[i] <- substr(experiment$midSurvey[[i]][12], 4, 20)
experiment$Q13[i] <- substr(experiment$midSurvey[[i]][13], 4, 20)
experiment$Q14[i] <- substr(experiment$midSurvey[[i]][14], 4, 20)
experiment$RTQ[i] <- substr(experiment$midSurvey[[i]][15], 4, 20)
}
levels <- c("Strongly Disagree", "Disagree", "Neutral","Agree", "Strongly Agree")
levels2 <- c("Yes","No")
experiment2 <- experiment %>%
mutate_at(.vars = vars(Q1:Q14), funs(factor(., levels = levels))) %>%
mutate_at(.vars = vars(RTQ), funs(factor(., levels = levels2)))
summary(experiment2[,8:22])
experiment3 <- experiment2
names(experiment3) <- c("userID", "room", "name", "round", "midSurvey", "batch", "_id", "1. The members of this team could work for a long time together"
, "2. Most of the members of this team would welcome the opportunity to work as a group again in the future." ,
"3. This team has the capacity for long-term success.",
"4. This team has what it takes to be effective in the future.",
"5. This team would work well together in the future." ,
" 6. This team has positioned itself well for continued success.",
" 7. This team has the ability to perform well in the future. ",
" 8. This team has the ability to function as an ongoing unit." ,
" 9. This team should continue to function as a unit. ",
" 10. This team has the resources to perform well in the future. ",
" 11. This team is well positioned for growth over time. ",
" 12. This team can develop to meet future challenges. ",
" 13. This team has the capacity to sustain itself. ",
" 14. This team has what it takes to endure in future performance episodes." ,
"Would you like to continue to work with this team?")
## Likert plots:
## Basic likert plot:
likert.out <- likert(experiment3[,8:21])
xtable(likert.out)
plot(likert.out)
rm(list=ls())
getwd()
setwd("/Users/allieblaising/desktop")
## Install packages outside of notebook environment.
install.packages(c("psych" ,"xtable", "GPArotation", "tidyverse", "purrr", "dplyr", "jsonlite", "likert", "lavaan", "dplyr", "stringr", "ggplot2",
"caret", "nFactors", "GPArotation", "Scale"))
library(psych)
library(xtable)
library(GPArotation)
library(psych)
library(dplyr)
library(jsonlite)
library(likert)
library(lavaan)
library(stringr)
library(ggplot2)
library(caret)
library(nFactors)
library(GPArotation)
library(Scale)
describe(experimentfactor)
describe(experimentfactor)
likert.out <- likert(experiment3[,8:21])
xtable(likert.out)
plot(likert.out)
ggplot(experiment2, aes(sum)) +
geom_histogram(binwidth=1) +
facet_wrap(~nominalQ1, ncol=1) +
xlab("Likert Scale Value") +
theme_bw()
## Likert plot grouping by Q15: "Would you like to work with this team again?":
likert.out.group <- likert(experiment2, grouping = experiment2$RTQ)
plot(likert.out.group, group.order=experiment2$RTQ) + theme(text=element_text(size=14))
plot(likert.out, centered=FALSE, low.color="firebrick",
high.color="forestgreen") +
theme(text=element_text(size=14))
## Likert heat plot:
plot(likert.out,	type='heat',	wrap=30,	text.size=4)
## Likert density curve:
plot(likert.out,	type='density')
## Likert density plot with a subset of questions:
likert.out2 <- likert(experiment3[,8:12])
plot(likert.out2,	type='density')
## Converting to numeric for stats analysis (need to figure out how to make this into 2 lines lol @me again)
for (i in 1:nrow(experiment2)) {
experiment2$nominalQ1 <- as.numeric(experiment2$Q1)
experiment2$nominalQ2 <- as.numeric(experiment2$Q2)
experiment2$nominalQ3 <- as.numeric(experiment2$Q3)
experiment2$nominalQ4 <- as.numeric(experiment2$Q4)
experiment2$nominalQ5 <- as.numeric(experiment2$Q5)
experiment2$nominalQ6 <- as.numeric(experiment2$Q6)
experiment2$nominalQ7 <- as.numeric(experiment2$Q7)
experiment2$nominalQ8 <- as.numeric(experiment2$Q8)
experiment2$nominalQ9 <- as.numeric(experiment2$Q9)
experiment2$nominalQ10 <- as.numeric(experiment2$Q10)
experiment2$nominalQ11 <- as.numeric(experiment2$Q11)
experiment2$nominalQ12 <- as.numeric(experiment2$Q12)
experiment2$nominalQ13 <- as.numeric(experiment2$Q13)
experiment2$nominalQ14 <- as.numeric(experiment2$Q14)
experiment2$nominalQ15 <- as.numeric(experiment2$RTQ)
}
## Loop to create sums for data analysis:
for (i in 1:nrow(experiment2)) {
experiment2$sum[i] <- sum(experiment2[,23:36][i])
}
## Assessing parametric normality:
hist(experiment2$sum,xlab="Sum of scores",main="")
## From the histogram above we can “unofficially”conclude that our data is relitively Normal,
## hance we are somewhat justified in using parametric statistical methodology.
## What is this saying: difference between sum of scores (high vs. low) and continue working
### with team Q.
boxplot(sum~nominalQ15,data=merged,names=c("Continue working with team",
"Stop working with team"))
boxplot(sum~blacklist,data=merged,names=c("Blacklist Team 1",
"Blacklist Team 2", "Indifferent"))
t.test(sum~nominalQ15, data=merged)
t.test(sum~blacklist, data=merged)
## First use a boxplot for visualization:
boxplot(sum~nominalQ15,data=merged,names=c("Continue working with team",
"Stop working with team"))
boxplot(sum~blacklist,data=merged,names=c("Blacklist Team 1",
"Blacklist Team 2", "Indifferent"))
t.test(sum~nominalQ15, data=merged)
t.test(sum~blacklist, data=merged)
## results indicate no, not a significant difference.
## breakdown by room & round:
roomAround1<- experiment2 %>%
filter(round=="1", room=="A")
roomAround2<- experiment2 %>%
filter(round=="2", room=="A")
roomBround1<- experiment2 %>%
filter(round=="1", room=="B")
roomBround2<- experiment2 %>%
filter(round=="2", room=="B")
## t-tests:
## round 1, room a:
t.test(sum~nominalQ15, data=roomAround1)
## round 1, room b:
t.test(sum~nominalQ15, data=roomBround1)
## round 2, room a:
t.test(sum~nominalQ15, data=roomAround2)
## round 2, room b:
t.test(sum~nominalQ15, data=roomBround2)
## Anova for survey questions, starting with repeat team question with sum of scores:
anova(lm(sum~RTQ,data=experiment2))
## Blacklist importing, cleaning & merging:
input2 = '[{"userID":"qL44K5kHvqZwHuzcAAAA","name":"niceWolf","midSurvey":"blacklist-q1=1","batch":1532028198071,"_id":"BGXqnkNyGqqpHP2c"}
,{"userID":"1pob6EHCHwzLa7nUAAAB","name":"culturedCat","midSurvey":"blacklist-q1=2","batch":1532028198071,"_id":"ELtcSJgRysGlBB77"}
,{"userID":"FGzkFbpp8ejWVSm0AAAC","name":"niceRabbit","midSurvey":"blacklist-q1=2","batch":1532028198071,"_id":"V37TWQFeRT0CwIf6"}
,{"userID":"-2emRdtAMYWaULymAAAD","name":"conventionalDeer","midSurvey":"blacklist-q1=2","batch":1532028198071,"_id":"uXGDrroAYDrKaIVh"}]'
blacklist = fromJSON(input2, simplifyDataFrame = TRUE)
blacklist <- as.data.frame(blacklist)
for (i in 1:length(blacklist$midSurvey)) {
blacklist$blacklist[i] <- substr(blacklist$midSurvey[i], 14, 20)
}
## Factoring for stats analysis
levels3 <- c(1:3)
blacklist <- blacklist %>%
mutate_at(.vars = vars(blacklist), funs(factor(., levels = levels3)))
## Factor summary / basic descriptive stats for likert :
merged <- merge(experiment2,blacklist,by="name")
## is there a significant difference between sum of survey question // blacklist (yes=1) (no=2) (don't care=3)
t.test(sum~blacklist, data=mergetest)
studentModel <- train(sum~blacklist, data=mergetest, method = "knn")
## analysis results:
## Scale validity
## Exploratory factor analysis introduction:
## Determine ## of factors;
mydata <- experiment2[,23:36]
ev <- eigen(cor(mydata)) # get eigenvalues
ap <- parallel(subject=nrow(mydata),var=ncol(mydata),
rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
## Optimal coordinates: n=1
#calculate the correlation matrix
corMat <- cor(mydata)
#display the correlation matrix
corMat
#use fa() to conduct an oblique principal-axis exploratory factor analysis
#save the solution to an R variable
solution <- fa(r = corMat, nfactors = 1, rotate = "oblimin", fm = "pa")
#display the solution output
solution
pca2 <- principal(data.matrix(mydata))
print(pca2)
KMO(data.matrix(experiment2[,8:12]))
## Calculating the number of factors
scale <- experiment2[, 23:36]
parallel <- fa.parallel(scale, fm = 'minres', fa = 'fa')
## Results show the maximum number of factors we can consider.
## Factor analysis now that we know # of factors:
## Using oblimin because we believe we believe that there is correlation in the factors.
threefactor <- fa(scale,nfactors = 3,rotate = "oblimin",fm="minres")
print(threefactor)
## Output shows loadings and factors
## Next, consider the loadings more than 0.3 and not loading on more than one factor:
print(threefactor$loadings,cutoff = 0.3)
## Based on this output we will consider X factors:
fourfactor <- fa(mydata,nfactors = 4,rotate = "oblimin",fm="minres")
print(fourfactor$loadings,cutoff = 0.3)
my_scale <- Scale(mydata,reverse=FALSE, col_names=c(1:14), items=mydata)
my_scale_pr <- PreProc(my_scale)
my_scale_it <- ItemAnalysis(my_scale_pr)
my_table <- ReportTable(my_scale_it)
## Suggestions for finding the right "test" for a null hypothesis of no differences
## in the responses between courses are not generally helpful. Significant can be
## misinterpreted; we need to base our findings not just on p-value, but also
## effect size and sig confidence intervals. It is also vital to provide a clear
## visualization of results that be quickly scanne and interpreted.
## Chi-Squared Test:
## One way to deal with "marmite" issue into binary classes and look at the number
## of responses falling into each category.
install.packages("corrr")
library(corrr)
## Average inter-item correlation: correlations between all items, averaged:
mydata %>% correlate()
class(nominalQ1)
inter_item <- mydata %>% correlate() %>% colMeans(na.rm = TRUE)
inter_item <- mydata %>% correlate()
mean(inter_item, na.rm=TRUE)
data.frame(inter_item) %>%
ggplot(aes(x = inter_item)) +
geom_histogram(bins = 10, alpha = .5) +
geom_vline(xintercept = mean(inter_item), color = "red") +
xlab("Mean inter-item correlation") +
theme_bw()
parallel <- fa.parallel(experiment2, fm = 'minres', fa = 'fa')
Results show the maximum number of factors we can consider.
## Factor analysis now that we know # of factors:
## Using oblimin because we believe we believe that there is correlation in the factors.
threefactor <- fa(data,nfactors = 3,rotate = "oblimin",fm="minres")
print(threefactor)
## Output shows loadings and factors
## Next, consider the loadings more than 0.3 and not loading on more than one factor:
print(threefactor$loadings,cutoff = 0.3)
## Based on this output we will consider X factors:
fourfactor <- fa(data,nfactors = 4,rotate = "oblimin",fm="minres")
print(fourfactor$loadings,cutoff = 0.3)
library(stats)
fit.2 <- factanal(mydata,factors=2,rotation="varimax")
n.factors <- 2
fit <- factanal(mydata,
n.factors,                # number of factors to extract
scores=c("regression"),
rotation="none")
print(fit, digits=2, cutoff=.3, sort=TRUE)
wilcox.test(merged$sum, merged$blacklist,Paired=TRUE, exact=FALSE)
wilcox.test(sum~room,data=merged)
kruskal.test(sum~round,data=merged)
merged$blacklist<- as.numeric(merged$blacklist)
wilcox.test(merged$sum, merged$blacklist, alternative = "two.sided")
mod<-polr(sum~blacklist + nominalQ15, data= merged,Hess=T)
summary(mod)
polr(formula = sum ~ blacklist + nominalQ15, data = merged, Hess = T)
coeffs <- coef(summary(mod))
p <- pnorm(abs(coeffs[, "t value"]), lower.tail = FALSE) * 2
cbind(coeffs, "p value" = round(p,3))
out <- factanal(covmat=cor(experimentfactor, use="complete.obs"), factors=5, rotation="varimax")
corMatrix <- cor(experimentfactor, use="complete.obs" )
experimentfactor <- experiment2[,23:36]
## Finding out the right number of factor to select for factor analysis.
## We will do this via parallel analysis
parallel<-fa.parallel(experimentfactor, fm='minres', fa='fa')
# Now that we’ve arrived at probable number number of factors, let’s start off with 3 as the number of factors.
# We will select oblique rotation (rotate = “oblimin”) as we believe that there is correlation
# in the factors. Note that Varimax rotation is used under the assumption that the factors are
# completely uncorrelated. We will use Ordinary Least Squared/Minres factoring (fm = “minres”),
# as it is known to provide results similar to Maximum Likelihood without assuming multivariate normal distribution and derives solutions through
# iterative eigendecomposition like principal axis.
threefactor <- fa(experimentfactor,nfactors = 3,rotate = "oblimin",fm="minres")
print(threefactor)
# The blue line shows eigenvalues of actual data and the two red lines (placed on top of each other)
# show simulated and resampled data. Here we look at the large drops in the actual data and spot the
# point where it levels off to the right. Also we locate the point of inflection -
# the point where the gap between simulated data and actual data tends to be minimum.
# Looking at this plot and parallel analysis, anywhere between 2 to 5 factors factors would
# be good choice.
print(threefactor$loadings,cutoff = 0.3)
fourfactor <- fa(experimentfactor,nfactors = 4,rotate = "oblimin",fm="minres")
fa.diagram(fourfactor)
## Adequacy test:
# The root mean square of residuals (RMSR) is 0.05. This is acceptable as this value should
# be closer to 0. Next we should check RMSEA (root mean square error of approximation) index.
# Its value, X, good fit if below 0.05.
# Finally, the Tucker-Lewis Index (TLI) is X - needs to be over 0.9.
experimentfactor <- experiment2[,23:36]
corMatrix <- cor(experimentfactor, use="complete.obs" )
out <- fa(r=corMatrix, factors=5 )
print(out$loadings, cutoff=0.3)
fa.diagram(out)
"complete.obs" )
out <- fa(r=corMatrix, factors=5 )
print( out$loadings, cutoff=0.3 )
fa.diagram(out)
describe(experimentfactor)
install.packages("corrr")
